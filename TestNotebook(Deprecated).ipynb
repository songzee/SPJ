{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shared/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "# As usual, a bit of setup\n",
    "import time\n",
    "from time import process_time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import LOUPE.WILLOW.loupe as lp\n",
    "import tensorflow as tf\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import csv\n",
    "import copy\n",
    "import math\n",
    "from utils.data_utils import temporal_indicator\n",
    "from utils.data_utils import temporal_pooling\n",
    "from utils.data_utils import export_vocabulary\n",
    "import sys\n",
    "import re\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load small training data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of examples:  99\n",
      "train_data.shape:  (590, 508)\n",
      "padded_proposals.shape:  (99, 500, 30)\n",
      "padded_framestamps.shape:  (99, 2, 30)\n"
     ]
    }
   ],
   "source": [
    "def video_preprocess():\n",
    "    # format\n",
    "    train_data = pd.read_csv(\"train_extreme_small.csv\")\n",
    "    train_data.rename( columns={'Unnamed: 0':'index'}, inplace=True )\n",
    "    train_data[\"duration\"] = train_data[\"duration\"].astype('float32')\n",
    "    train_data[\"t_init\"], train_data[\"t_end\"] = train_data[\"timestamps\"].str.split(\", \", 1).str\n",
    "    train_data[\"t_init\"] = train_data[\"t_init\"].str.strip(\"[\")\n",
    "    train_data[\"t_end\"] = train_data[\"t_end\"].str.strip(\"]\")\n",
    "    train_data[\"t_init\"] = train_data[\"t_init\"].astype('float32')\n",
    "    train_data[\"t_end\"] = train_data[\"t_end\"].astype('float32')\n",
    "    train_data = train_data.drop('timestamps', 1)\n",
    "\n",
    "    # pool\n",
    "    filename = \"/home/martnzjulio_a/c3d_data/sub_activitynet_v1-3.c3d.hdf5\"\n",
    "    video_feature_representation = h5py.File(filename, 'r')\n",
    "    train_ids = train_data['id'].unique()\n",
    "    f_inits = []\n",
    "    f_ends = []\n",
    "    max_pooled_representations = []\n",
    "    max_proposals = 0\n",
    "    padded_proposals = np.zeros((99,500,30))\n",
    "    padded_framestamps = -1*np.ones((99,2,30))\n",
    "    for v,video_id in enumerate(train_ids):\n",
    "        #print(\"video id: \", video_id)\n",
    "        temp = train_data[train_data['id']==video_id].reset_index()\n",
    "        C3D_features = video_feature_representation[\"v_QOlSCBRmfWY\"]['c3d_features'].value\n",
    "\n",
    "        if max_proposals < temp.shape[0]:\n",
    "            max_proposals = temp.shape[0]\n",
    "\n",
    "        for i in range(temp.shape[0]):\n",
    "\n",
    "            # get time info\n",
    "            duration = temp[\"duration\"][i]\n",
    "            t_init = temp[\"t_init\"][i]\n",
    "            t_end = temp[\"t_end\"][i]\n",
    "            num_frames = C3D_features.shape[0]\n",
    "\n",
    "            # compute start and end frame\n",
    "            f_init = int(round((t_init/duration)*num_frames))\n",
    "            f_end = int(round((t_end/duration)*num_frames))\n",
    "            #print(\"f_init: \", f_init, \"t_init: \", t_init)\n",
    "            #print(\"f_end: \", f_end, \"t_end: \", t_end)\n",
    "\n",
    "            # get max pool\n",
    "            if f_init <= f_end:\n",
    "                max_pooled_rep = temporal_pooling(C3D_features[f_init:f_end],\"max\")\n",
    "            else:\n",
    "                max_pooled_rep = temporal_pooling(C3D_features[f_end:f_init],\"max\")\n",
    "\n",
    "            # append info\n",
    "            f_inits.append(f_init)\n",
    "            f_ends.append(f_end)\n",
    "            max_pooled_representations.append(max_pooled_rep)\n",
    "            padded_proposals[v,:,i] = max_pooled_rep\n",
    "            padded_framestamps[v,0,i] = f_init\n",
    "            padded_framestamps[v,1,i] = f_end\n",
    "\n",
    "\n",
    "    f_inits = np.array(f_inits)\n",
    "    f_inits = pd.DataFrame({'f_init': f_inits})\n",
    "    f_ends = np.array(f_ends) \n",
    "    f_ends = pd.DataFrame({'f_end': f_ends})\n",
    "\n",
    "    max_pooled_representations = np.array(max_pooled_representations)\n",
    "    C3D_feature_column_names = [\"h\" + str(i) for i in range(max_pooled_representations.shape[1])] \n",
    "    max_pooled_representations = pd.DataFrame(max_pooled_representations, columns=C3D_feature_column_names)\n",
    "\n",
    "    train_data = pd.concat([train_data, f_inits, f_ends, max_pooled_representations], axis=1)\n",
    "    train_data.to_pickle(\"train_data\")\n",
    "\n",
    "    print(\"number of examples: \", train_ids.shape[0])\n",
    "    print(\"train_data.shape: \", train_data.shape)\n",
    "    print(\"padded_proposals.shape: \", padded_proposals.shape)\n",
    "    print(\"padded_framestamps.shape: \", padded_framestamps.shape) \n",
    "    return train_ids,train_data,padded_proposals,padded_framestamps\n",
    "    \n",
    "train_ids,train_data,padded_proposals,padded_framestamps = video_preprocess()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get word2id in sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "_PAD = b\"<pad>\"\n",
    "_UNK = b\"<unk>\"\n",
    "_STA = b\"<sta>\"\n",
    "_END = b\"<end>\"\n",
    "_START_VOCAB = [_PAD,_UNK,_STA,_END]\n",
    "PAD_ID = 0\n",
    "UNK_ID = 1\n",
    "STA_ID = 2\n",
    "END_ID = 3\n",
    "\n",
    "def caption_preprocess():\n",
    "\n",
    "    \n",
    "    train_voc = pd.read_csv(\"train_all.csv\")\n",
    "    train_voc.rename( columns={'Unnamed: 0':'index'}, inplace=True )\n",
    "    train_voc[\"duration\"] = train_voc[\"duration\"].astype('float32')\n",
    "    train_voc[\"t_init\"], train_voc[\"t_end\"] = train_voc[\"timestamps\"].str.split(\", \", 1).str\n",
    "    train_voc[\"t_init\"] = train_voc[\"t_init\"].str.strip(\"[\")\n",
    "    train_voc[\"t_end\"] = train_voc[\"t_end\"].str.strip(\"]\")\n",
    "    train_voc[\"t_init\"] = train_voc[\"t_init\"].astype('float32')\n",
    "    train_voc[\"t_end\"] = train_voc[\"t_end\"].astype('float32')\n",
    "    train_voc = train_voc.drop('timestamps', 1)\n",
    "\n",
    "    export_vocabulary(train_voc)\n",
    "    df = pd.read_csv('vocabulary.csv')\n",
    "    voc = df[\"Unnamed: 0\"].tolist()\n",
    "    vocabulary = []\n",
    "    for word in voc:\n",
    "        if word.isalpha():\n",
    "            vocabulary.append(word)\n",
    "            \n",
    "    vocab_size = len(vocabulary)\n",
    "    return vocabulary,vocab_size\n",
    "    \n",
    "\n",
    "def get_wordvector(emb_dim,vocab_size,vocabulary):\n",
    "    \"\"\"Reads from original word lib file and returns embedding matrix and\n",
    "    mappings from words to word ids.\n",
    "\n",
    "    Returns:\n",
    "      emb_matrix: Numpy array shape (len(vocabulary), word_dim) containing word embeddings\n",
    "        (plus PAD and UNK embeddings in first 4 rows).\n",
    "        The rows of emb_matrix correspond to the word ids given in word2id and id2word\n",
    "      word2id: dictionary mapping word (string) to word id (int)\n",
    "      id2word: dictionary mapping word id (int) to word (string)\n",
    "    \"\"\"\n",
    "    \n",
    "    vocabulary = _START_VOCAB + vocabulary\n",
    "\n",
    "    emb_matrix = np.zeros((vocab_size + len(_START_VOCAB), emb_dim))\n",
    "    word2id = {}\n",
    "    id2word = {}\n",
    "\n",
    "    random_init = True\n",
    "    # randomly initialize all the tokens\n",
    "    emb_matrix[:, :] = np.random.randn(vocab_size + len(_START_VOCAB), emb_dim)\n",
    "\n",
    "    # put start tokens in the dictionaries\n",
    "    idx = 0\n",
    "    for word in vocabulary:\n",
    "        word2id[word] = idx\n",
    "        id2word[idx] = word\n",
    "        idx += 1\n",
    "\n",
    "\n",
    "    final_vocab_size = vocab_size + len(_START_VOCAB)\n",
    "    assert len(word2id) == final_vocab_size\n",
    "    assert len(id2word) == final_vocab_size\n",
    "    assert idx == final_vocab_size\n",
    "\n",
    "    return emb_matrix, word2id, id2word\n",
    "#Changed by Songze\n",
    "def split_by_whitespace(sentence):\n",
    "    words = []\n",
    "    for space_separated_fragment in sentence.strip().split():\n",
    "        words.extend(re.split(\" \", space_separated_fragment))\n",
    "    return [w for w in words if w]\n",
    "\n",
    "\n",
    "def intstr_to_intlist(string):\n",
    "    \"\"\"Given a string e.g. '311 9 1334 635 6192 56 639', returns as a list of integers\"\"\"\n",
    "    return [int(s) for s in string.split()]\n",
    "\n",
    "\n",
    "def sentence_to_token_ids(sentence, word2id):\n",
    "    \"\"\"Turns an already-tokenized sentence string into word indices\n",
    "    e.g. \"i do n't know\" -> [9, 32, 16, 96]\n",
    "    Note any token that isn't in the word2id mapping gets mapped to the id for UNK\n",
    "    \"\"\"\n",
    "    tokens = split_by_whitespace(sentence) # list of strings\n",
    "    ids = [word2id.get(w.lower(), UNK_ID) for w in tokens]\n",
    "    return tokens, ids\n",
    "\n",
    "\n",
    "def padded(token_batch, batch_pad=0):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "      token_batch: List (length batch size) of lists of ints.\n",
    "      batch_pad: Int. Length to pad to. If 0, pad to maximum length sequence in token_batch.\n",
    "    Returns:\n",
    "      List (length batch_size) of padded lists of ints.\n",
    "        All are same length - batch_pad if batch_pad!=0, otherwise the maximum length in token_batch\n",
    "    \"\"\"\n",
    "    maxlen = max(lambda x: len(x), token_batch) if batch_pad == 0 else batch_pad\n",
    "    res = [STA_ID]+token_batch+[END_ID]+[PAD_ID] * (maxlen - len(token_batch)-2)\n",
    "\n",
    "    return res\n",
    "\n",
    "def get_padded_sentences_id(pad_len,train_ids):\n",
    "    all_padded_sentences = np.zeros((99,pad_len,30))\n",
    "    for v,video_id in enumerate(train_ids):\n",
    "        temp = train_data[train_data['id']==video_id].reset_index()\n",
    "        for i in range(temp.shape[0]):\n",
    "            words,ids = sentence_to_token_ids(temp['sentences'][i][:-1],word2id)\n",
    "            ids_pad = padded(ids,pad_len)\n",
    "            all_padded_sentences[v,:,i] = ids_pad\n",
    "\n",
    "\n",
    "    all_padded_sentences_2 = np.zeros((99,pad_len+1,30))\n",
    "    for v,video_id in enumerate(train_ids):\n",
    "        temp = train_data[train_data['id']==video_id].reset_index()\n",
    "        for i in range(temp.shape[0]):\n",
    "            words,ids = sentence_to_token_ids(temp['sentences'][i][:-1],word2id)\n",
    "            ids_pad = padded(ids,pad_len+1)\n",
    "            all_padded_sentences_2[v,:,i] = ids_pad\n",
    "    all_padded_sentences_id = np.array(all_padded_sentences).astype(int)\n",
    "            \n",
    "    return all_padded_sentences,all_padded_sentences_2,all_padded_sentences_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words in all captions:  504895\n",
      "Vocabulary Size (Unique):  13001\n",
      "all_padded_sentences_2.shape:  (99, 51, 30)\n"
     ]
    }
   ],
   "source": [
    "embedding_size =512\n",
    "vocabulary,vocab_size = caption_preprocess()\n",
    "emb_matrix,word2id,id2word = get_wordvector(embedding_size,vocab_size,vocabulary)\n",
    "pad_len = 50\n",
    "all_padded_sentences,all_padded_sentences_2,all_padded_sentences_id = get_padded_sentences_id(pad_len,train_ids)     \n",
    "print(\"all_padded_sentences_2.shape: \", all_padded_sentences_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_module(H, Ipast, Ifuture, num_proposals, num_c3d_features, num_steps, batch_size,eps = 1e-10):\n",
    "    \"\"\"\n",
    "    Implements the attention module: see https://cs.stanford.edu/people/ranjaykrishna/densevid/\n",
    "    \n",
    "    Arguments:\n",
    "    H -- input dataset placeholder, of shape = [None, N, K] and dtype \"float\"\n",
    "    Ipast -- placeholder for the indicators of past, shape = [None, K, K] and dtype \"float\"\n",
    "    Ifuture == placeholder for the indicators of future, shape = [None, K, K] and dtype \"float\"\n",
    "    parameters -- python dictionary containing your parameters \"Wa\", \"ba\", sapes [N,N] and [N,1] respectively\n",
    "\n",
    "    Returns:\n",
    "    Hout -- concatenated output (hpast, h, hfuture), shape = [batch_size, 3*num_c3d_features, num_proposals]\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    Wa = tf.get_variable(\"Wa\", [num_c3d_features,num_c3d_features], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    ba = tf.get_variable(\"ba\", [num_c3d_features,1], initializer = tf.zeros_initializer())\n",
    "\n",
    "    # forward pass\n",
    "    W = tf.transpose(tf.tensordot(Wa,tf.transpose(H,perm=[1,2,0]),axes=[[1], [0]]),perm=[2,0,1]) + ba # shape: [None,num_proposals,num_proposals]\n",
    "    A = tf.matmul(tf.transpose(W,perm=[0,2,1]),H) # shape: [None,num_proposals,num_proposals]\n",
    "    A_flat = tf.reshape(A, [-1, num_proposals*num_proposals]) # shape: [None,num_proposals*num_proposals]\n",
    "\n",
    "    # future features\n",
    "    Ifuture_flat = tf.reshape(Ifuture, [-1, num_proposals*num_proposals]) # shape: [None,K*K]\n",
    "    Afuture = tf.reshape(tf.multiply(Ifuture_flat,A_flat),[-1,num_proposals,num_proposals]) # shape: [None,K,K]\n",
    "    Zfuture = tf.reduce_sum(Ifuture,axis=2)+eps # shape: [None,num_proposals]\n",
    "    Hfuture = tf.transpose(tf.transpose(tf.matmul(H,tf.transpose(Afuture,perm=[0,2,1])),perm=[1,0,2])/Zfuture,perm=[1,0,2]) # shape: [None,num_c3d_features,num_proposals]\n",
    "\n",
    "    # past features\n",
    "    Ipast_flat = tf.reshape(Ipast, [-1, num_proposals*num_proposals]) # shape: [None,num_proposals*num_proposals]\n",
    "    Apast = tf.reshape(tf.multiply(Ipast_flat,A_flat),[-1,num_proposals,num_proposals]) # shape: [None,num_proposals,num_proposals]\n",
    "    Zpast = tf.reduce_sum(Ipast,axis=2)+eps # shape: [None,num_proposals]\n",
    "    Hpast = tf.transpose(tf.transpose(tf.matmul(H,tf.transpose(Apast,perm=[0,2,1])),perm=[1,0,2])/Zfuture,perm=[1,0,2]) # shape: [None,num_c3d_features,num_proposals]\n",
    "\n",
    "    # stacked features\n",
    "    Hout = tf.concat([Hpast, H, Hfuture], 1)\n",
    "    \n",
    "    return Hout\n",
    "\n",
    "def language_module(Hout, x, num_classes, hidden_dim, num_steps, num_proposals, num_layers, batch_size):\n",
    "    '''\n",
    "    Inputs: \n",
    "      number of classes\n",
    "      hidden_dim = number units in lstm and word embedding\n",
    "      num_steps, length of captions\n",
    "      num_steps\n",
    "      num_layers \n",
    "      batch_size\n",
    "    '''\n",
    "    \n",
    "    Hout = tf.transpose(Hout, perm=[0,2,1])\n",
    "    Hout = tf.reshape(Hout, [-1, 1500])    \n",
    "    \n",
    "    feature_inputs = tf.expand_dims(tf.layers.dense(inputs=Hout,units=hidden_dim,activation=tf.nn.relu),1)\n",
    "\n",
    "\n",
    "    embeddings = tf.get_variable('embedding_matrix', [num_classes, hidden_dim])\n",
    "    embedding_inputs = tf.nn.embedding_lookup(embeddings, tf.reshape(x,[-1,num_steps]))\n",
    "                                              \n",
    "    lstm_inputs = tf.concat(values=[feature_inputs, embedding_inputs],axis=1)                           \n",
    "    \n",
    "    lstm_cell = tf.nn.rnn_cell.LSTMCell(num_units=hidden_dim,state_is_tuple=True)\n",
    "    lstm_cells = tf.nn.rnn_cell.MultiRNNCell([lstm_cell] * num_layers, state_is_tuple=True)\n",
    "    initial_state = lstm_cells.zero_state(batch_size*num_proposals, tf.float32)\n",
    "    lstm_outputs, final_state = tf.nn.dynamic_rnn(cell=lstm_cells,inputs=lstm_inputs,initial_state=initial_state)                                  \n",
    "                                              \n",
    "    logits = tf.layers.dense(inputs=tf.reshape(lstm_outputs,[-1,hidden_dim]),units=num_classes)\n",
    "                                         \n",
    "    predictions = tf.argmax(logits,1)\n",
    "    predictions = tf.reshape(predictions, [batch_size,num_proposals,num_steps+1])\n",
    "    \n",
    "    logits = tf.reshape(logits, [batch_size,num_proposals,num_steps+1,num_classes])\n",
    "                                                                            \n",
    "    return predictions, logits\n",
    "\n",
    "def caption_cost(y, logits, num_classes, num_proposals,num_steps,batch_size):\n",
    "\n",
    "    loss = tf.reduce_sum(\n",
    "        tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "            logits=tf.reshape(logits,[-1,num_classes]), \n",
    "            labels=tf.reshape(y,[-1])\n",
    "        )\n",
    "    )\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Forward Pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_train = padded_proposals.astype(np.float32)\n",
    "framestamps = padded_framestamps\n",
    "Ipast = temporal_indicator(framestamps, mode=\"past\")\n",
    "Ipast_train = Ipast.astype(np.float32)\n",
    "Ifuture = temporal_indicator(framestamps, mode=\"future\")\n",
    "Ifuture_train = Ifuture.astype(np.float32)\n",
    "emb_matrix, word2id, id2word = get_wordvector(embedding_size,vocab_size,vocabulary) #changed by Songze\n",
    "sentence_ids = all_padded_sentences_id\n",
    "Ycaptions = copy.deepcopy(all_padded_sentences_2) # holds i\n",
    "Xcaptions = copy.deepcopy(all_padded_sentences)\n",
    "Xcaptions = Xcaptions.astype(np.int32)\n",
    "Ycaptions = Ycaptions.astype(np.int32)\n",
    "Xcaptions_train = np.transpose(Xcaptions,axes=(0,2,1))\n",
    "Ycaptions_train = np.transpose(Ycaptions,axes=(0,2,1))\n",
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "num_c3d_features = 500\n",
    "num_classes = len(word2id)\n",
    "\n",
    "hidden_dim = 512\n",
    "num_steps = 50\n",
    "num_proposals = 30\n",
    "num_layers = 2\n",
    "batch_size = 9\n",
    "\n",
    "tf.reset_default_graph()\n",
    "# create placeholders\n",
    "H = tf.placeholder(tf.float32,shape=[batch_size, num_c3d_features, num_proposals], name=\"H\")\n",
    "Ipast = tf.placeholder(tf.float32, shape=[batch_size, num_proposals, num_proposals], name=\"Ipast\")\n",
    "Ifuture = tf.placeholder(tf.float32, shape=[batch_size, num_proposals, num_proposals], name=\"Ifuture\")\n",
    "x = tf.placeholder(tf.int32, [batch_size, num_proposals, num_steps], name=\"x\")\n",
    "y = tf.placeholder(tf.int32, [batch_size, num_proposals, num_steps+1], name=\"y\")\n",
    "\n",
    "# forward pass\n",
    "Hout = attention_module(H, Ipast, Ifuture, num_proposals, num_c3d_features, num_steps, batch_size)\n",
    "predictions, logits = language_module(Hout, x, num_classes, hidden_dim, num_steps, num_proposals, num_layers, batch_size)\n",
    "cap_loss = caption_cost(y, logits, num_classes, num_proposals,num_steps,batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(H_train, Ipast_train, Ifuture_train, Ycaptions_train, Xcaptions_train,word2id_len,learning_rate, num_epochs = 5, minibatch_size = 9, print_cost = True,num_layers = 2,hidden_dim = 512):\n",
    "    \"\"\"\n",
    "    Implements a tensorflow neural network: C3D->DAPS->ATTENTION->CAPTIONING\n",
    "    \n",
    "    Arguments:\n",
    "    H_train -- training set, of shape = [n_train,num_c3d_features,num_proposals]\n",
    "    Y_train -- caption labels, of shape = [n_train,num_proposals,num_steps+1]\n",
    "    H_test -- training set, of shape = [n_test,num_c3d_features,num_proposals]\n",
    "    Y_test -- caption labels, of shape = [n_test,num_proposals,num_steps+1]\n",
    "    learning_rate -- learning rate of the optimization\n",
    "    num_epochs -- number of epochs of the optimization loop\n",
    "    minibatch_size -- size of a minibatch\n",
    "    print_cost -- True to print the cost every 100 epochs\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "    checkpoint_dir = \"/home/martnzjulio_a/checkpoints/\"\n",
    "    \n",
    "    batch_size = minibatch_size\n",
    "    \n",
    "    # to be able to rerun the model without overwriting tf variables\n",
    "    tf.reset_default_graph()    \n",
    "    \n",
    "    # to keep consistent results\n",
    "    tf.set_random_seed(1)                             \n",
    "    seed = 3                                         \n",
    "    \n",
    "    # size values\n",
    "    (n_train,num_c3d_features,num_proposals) = H_train.shape                        \n",
    "    (_,_,num_steps) = Xcaptions_train.shape\n",
    "    num_classes = word2id_len\n",
    "    \n",
    "    #print(\"n_train \", n_train)\n",
    "    #print(\"num_c3d_features \", num_c3d_features)\n",
    "    #print(\"num_proposals: \", num_proposals)\n",
    "    #print(\"num_steps: \", num_steps)\n",
    "    \n",
    "    # to keep track of costs\n",
    "    costs = []\n",
    "    \n",
    "    # keep track of global epoch number\n",
    "    global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "    \n",
    "    # create placeholders\n",
    "    H = tf.placeholder(tf.float32,shape=[batch_size, num_c3d_features, num_proposals], name=\"H\")\n",
    "    Ipast = tf.placeholder(tf.float32, shape=[batch_size, num_proposals, num_proposals], name=\"Ipast\")\n",
    "    Ifuture = tf.placeholder(tf.float32, shape=[batch_size, num_proposals, num_proposals], name=\"Ifuture\")\n",
    "    x = tf.placeholder(tf.int32, [batch_size, num_proposals, num_steps], name=\"x\")\n",
    "    y = tf.placeholder(tf.int32, [batch_size, num_proposals, num_steps+1], name=\"y\")\n",
    "    \n",
    "    # attention module\n",
    "    #attention_module(K,N, batch_size)\n",
    "    Hout = attention_module(\n",
    "        H,\n",
    "        Ipast,\n",
    "        Ifuture,\n",
    "        num_proposals, \n",
    "        num_c3d_features,\n",
    "        num_steps,\n",
    "        batch_size\n",
    "    )\n",
    "    \n",
    "    # language module\n",
    "    #language_module(Hout, num_classes, hidden_dim, num_steps, num_proposals, num_layers, batch_size)\n",
    "    predictions, logits = language_module(\n",
    "        Hout, \n",
    "        x,\n",
    "        num_classes, \n",
    "        hidden_dim, \n",
    "        num_steps, \n",
    "        num_proposals, \n",
    "        num_layers, \n",
    "        batch_size\n",
    "    )\n",
    "    \n",
    "    # cost\n",
    "    # caption_cost(logits, num_classes, num_proposals,num_steps,batch_size)\n",
    "    cap_loss = caption_cost(\n",
    "        y,\n",
    "        logits, \n",
    "        num_classes, \n",
    "        num_proposals, \n",
    "        num_steps, \n",
    "        batch_size\n",
    "    )\n",
    "    \n",
    "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer.\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cap_loss, global_step=global_step)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Initialize all the variables\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    # Add ops to save and restore all the variables.\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    # Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:\n",
    "           \n",
    "        # check for latest checkpoint\n",
    "        latest_checkpoint = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "        if latest_checkpoint == None:\n",
    "            # If no check point run the initialization\n",
    "            print(\"No checkpint exists, initializing parameters...\")\n",
    "            sess.run(init)\n",
    "        else:\n",
    "            print(\"Restoring from latest checkpoint...\")\n",
    "            saver.restore(sess, latest_checkpoint)\n",
    "        \n",
    "        # Do the training loop\n",
    "        start = process_time()\n",
    "        for epoch in range(num_epochs):\n",
    "            #print(\"epoch: \", epoch)\n",
    "\n",
    "            epoch_cost = 0.                       # Defines a cost related to an epoch\n",
    "            num_minibatches = int(n_train / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "            seed = seed + 1\n",
    "            minibatches = random_mini_batches(H_train, Ipast_train, Ifuture_train, Ycaptions_train, Xcaptions_train, minibatch_size, seed = 0)\n",
    "\n",
    "            for counter,minibatch in enumerate(minibatches):\n",
    "                #print(\"counter: \", counter)\n",
    "\n",
    "                # Select a minibatch\n",
    "                (minibatch_H, minibatch_Ipast, minibatch_Ifuture, minibatch_Ycaptions, minibatch_Xcaptions) = minibatch\n",
    "                #print(\"minibatch_H.shape: \", minibatch_H.shape)\n",
    "                #print(\"minibatch_Ipast.shape: \", minibatch_Ipast.shape)\n",
    "                #print(\"minibatch_Ifuture.shape: \", minibatch_Ifuture.shape)\n",
    "                #print(\"minibatch_Ycaptions.shape: \", minibatch_Ycaptions.shape)\n",
    "                #print(\"minibatch_Xcaptions.shape: \", minibatch_Xcaptions.shape)\n",
    "                \n",
    "                # The line that runs the graph on a minibatch.\n",
    "                _ , minibatch_cost = sess.run([optimizer, cap_loss], feed_dict={H: minibatch_H, Ipast: minibatch_Ipast, Ifuture: minibatch_Ifuture, x: minibatch_Xcaptions, y: minibatch_Ycaptions})\n",
    "\n",
    "                epoch_cost += minibatch_cost / num_minibatches\n",
    "                \n",
    "            # print cost every epoch\n",
    "            if print_cost == True:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "                costs.append(epoch_cost)\n",
    "            \n",
    "            # We save our model\n",
    "            if epoch % 20 == 0:\n",
    "                saver.save(sess, checkpoint_dir + 'model', global_step = global_step) # write_meta_graph=False\n",
    "                    \n",
    "        end = process_time()   \n",
    "        print(\"time elapased: \", end - start)\n",
    "        print()\n",
    "        # plot the cost\n",
    "        final_costs = np.squeeze(costs)\n",
    "        plt.plot(final_costs)\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # lets save the parameters in a variable\n",
    "        #parameters = sess.run(parameters)\n",
    "        #print (\"Parameters have been trained!\")\n",
    "\n",
    "        # Calculate the correct predictions\n",
    "        #correct_prediction = tf.equal(tf.argmax(Z3), tf.argmax(Y))\n",
    "\n",
    "        # Calculate accuracy on the test set\n",
    "        #accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "        #print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n",
    "        #print (\"Test Accuracy:\", accuracy.eval({X: X_test, Y: Y_test}))\n",
    "        \n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_mini_batches(H, Ipast, Ifuture, Ycaptions, Xcaptions, mini_batch_size = 9, seed = 0):\n",
    "    \"\"\"\n",
    "    Creates a list of random minibatches from (H, Ipast, Ifuture, Ycaptions, Xcaptions)\n",
    "    \n",
    "    Arguments:\n",
    "    H -- training set, of shape = [n_train,num_c3d_features,num_proposals]\n",
    "    Y -- caption labels, of shape = [n_train,num_proposals,num_steps+1]\n",
    "    mini_batch_size - size of the mini-batches, integer\n",
    "    seed -- this is only for the purpose of grading, so that you're \"random minibatches are the same as ours.\n",
    "    \n",
    "    Returns:\n",
    "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    X -- input data, of shape (input size, number of examples)\n",
    "    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)\n",
    "    mini_batch_size - size of the mini-batches, integer\n",
    "    seed -- this is only for the purpose of grading, so that you're \"random minibatches are the same as ours.\n",
    "    \n",
    "    Returns:\n",
    "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
    "     \"\"\"\n",
    "    \n",
    "    m = H.shape[0]                  # number of training examples\n",
    "    mini_batches = []\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Step 1: Shuffle (H, Ipast, Ifuture, Ycaptions, Xcaptions)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_H = H[permutation]\n",
    "    shuffled_Ipast = Ipast[permutation]\n",
    "    shuffled_Ifuture = Ifuture[permutation]\n",
    "    shuffled_Ycaptions = Ycaptions[permutation]\n",
    "    shuffled_Xcaptions = Xcaptions[permutation]\n",
    "    \n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        mini_batch_H = shuffled_H[k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
    "        mini_batch_Ipast = shuffled_Ipast[k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
    "        mini_batch_Ifuture = shuffled_Ifuture[k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
    "        mini_batch_Ycaptions = shuffled_Ycaptions[k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
    "        mini_batch_Xcaptions = shuffled_Xcaptions[k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
    "        mini_batch = (mini_batch_H, mini_batch_Ipast, mini_batch_Ifuture, mini_batch_Ycaptions, mini_batch_Xcaptions)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        mini_batch_H = shuffled_H[num_complete_minibatches * mini_batch_size : m]\n",
    "        mini_batch_Ipast = shuffled_Ipast[num_complete_minibatches * mini_batch_size : m]\n",
    "        mini_batch_Ifuture = shuffled_Ifuture[num_complete_minibatches * mini_batch_size : m]\n",
    "        mini_batch_Ycaptions = shuffled_Ycaptions[num_complete_minibatches * mini_batch_size : m]\n",
    "        mini_batch_Xcaptions = shuffled_Xcaptions[num_complete_minibatches * mini_batch_size : m]\n",
    "        mini_batch = (mini_batch_H, mini_batch_Ipast, mini_batch_Ifuture, mini_batch_Ycaptions, mini_batch_Xcaptions)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring from latest checkpoint...\n",
      "INFO:tensorflow:Restoring parameters from /home/martnzjulio_a/checkpoints/model-22\n",
      "Cost after epoch 0: 8615.745517\n",
      "Cost after epoch 1: 8261.401323\n",
      "Cost after epoch 2: 8011.641025\n",
      "Cost after epoch 3: 7873.134766\n",
      "Cost after epoch 4: 7802.168679\n",
      "time elapased:  37.561134425000006\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0c196f64a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Case\n",
    "\n",
    "# input features\n",
    "H = padded_proposals.astype(np.float32)\n",
    "\n",
    "# input framstamps [f_init, f_end]\n",
    "framestamps = padded_framestamps\n",
    "\n",
    "# Indicators for past and future\n",
    "Ipast = temporal_indicator(framestamps, mode=\"past\").astype(np.float32)\n",
    "Ifuture = temporal_indicator(framestamps, mode=\"future\").astype(np.float32)\n",
    "\n",
    "# Word Embedding Matrix\n",
    "emb_matrix, word2id, id2word = get_wordvector(embedding_size,vocab_size,vocabulary) #changed by Songze\n",
    "\n",
    "sentence_ids = all_padded_sentences_id\n",
    "Ycaptions = copy.deepcopy(all_padded_sentences_2) \n",
    "Xcaptions = copy.deepcopy(all_padded_sentences)\n",
    "Xcaptions = np.transpose(Xcaptions,axes=(0,2,1)).astype(np.int32)\n",
    "Ycaptions = np.transpose(Ycaptions,axes=(0,2,1)).astype(np.int32)\n",
    "\n",
    "learning_rate = 0.001\n",
    "num_epochs = 5\n",
    "model(H, Ipast, Ifuture, Ycaptions, Xcaptions,len(word2id), learning_rate, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ignore Code Below for Now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_loss(self):\n",
    "       \"\"\"\n",
    "       Add loss computation to the graph.\n",
    "\n",
    "       Uses:\n",
    "         self.logits_start: shape (batch_size, context_len)\n",
    "           IMPORTANT: Assumes that self.logits_start is masked (i.e. has -large in masked locations).\n",
    "           That's because the tf.nn.sparse_softmax_cross_entropy_with_logits\n",
    "           function applies softmax and then computes cross-entropy loss.\n",
    "           So you need to apply masking to the logits (by subtracting large\n",
    "           number in the padding location) BEFORE you pass to the\n",
    "           sparse_softmax_cross_entropy_with_logits function.\n",
    "\n",
    "         self.ans_span: shape (batch_size, 2)\n",
    "           Contains the gold start and end locations\n",
    "\n",
    "       Defines:\n",
    "         self.loss_start, self.loss_end, self.loss: all scalar tensors\n",
    "       \"\"\"\n",
    "       with vs.variable_scope(\"loss\"):\n",
    "\n",
    "           # Calculate loss for prediction of start position\n",
    "           loss_start = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=self.logits_start, labels=self.ans_span[:, 0]) # loss_start has shape (batch_size)\n",
    "           self.loss_start = tf.reduce_mean(loss_start) # scalar. avg across batch\n",
    "           tf.summary.scalar('loss_start', self.loss_start) # log to tensorboard\n",
    "\n",
    "           # Calculate loss for prediction of end position\n",
    "           loss_end = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=self.logits_end, labels=self.ans_span[:, 1])\n",
    "           self.loss_end = tf.reduce_mean(loss_end)\n",
    "           tf.summary.scalar('loss_end', self.loss_end)\n",
    "\n",
    "           # Add the two losses\n",
    "           self.loss = self.loss_start + self.loss_end\n",
    "           tf.summary.scalar('loss', self.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(Hout,Sout,embeddings,word2id,rnn_outputs,x,y):\n",
    "    state_size = 512\n",
    "    batch_size = Hout.shape[0]\n",
    "    num_steps = Sout[1]\n",
    "    num_classes = embeddings[1]\n",
    "    num_layers = 2\n",
    "    initializer = Hout\n",
    "    \n",
    "    with tf.variable_scope('softmax'):\n",
    "        W = tf.get_variable('W', [state_size, num_classes])\n",
    "        b = tf.get_variable('b', [num_classes], initializer=tf.constant_initializer(0.0))\n",
    "    #reshape rnn_outputs and y so we can get the logits in a single matmul\n",
    "    rnn_outputs = tf.reshape(rnn_outputs, [-1, state_size])\n",
    "    y_reshaped = tf.reshape(y, [-1])\n",
    "    logits = tf.matmul(rnn_outputs, W) + b\n",
    "    losses = tf.reshape(tf.nn.sparse_softmax_cross_entropy_with_logits(logits, y_reshaped),[batch_size, num_steps])\n",
    "    loss_by_timestep = tf.reduce_mean(losses, reduction_indices=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_embedding_layer(sentence_ids,emb_matrix):\n",
    "    \"\"\"\n",
    "    Adds word embedding layer to the graph.\n",
    "\n",
    "    Inputs:\n",
    "      emb_matrix: shape (400002, embedding_size).\n",
    "      The Glove vectors, plus vectors for PAD and UNK.\n",
    "    \"\"\"\n",
    "    #with vs.variable_scope(\"embeddings\"):\n",
    "\n",
    "    # Note: the embedding matrix is a tf.constant which means it's not a trainable parameter\n",
    "    embedding_matrix = tf.constant(emb_matrix, dtype=tf.float32, name=\"emb_matrix\") # shape (400002, embedding_size)\n",
    "\n",
    "    # Get the word embeddings for the caption\n",
    "    # using the placeholders caption\n",
    "    #cap_embs = embedding_ops.embedding_lookup(embedding_matrix, sentence_ids) # shape (batch_size, context_len, embedding_size)\n",
    "    cap_embs = tf.nn.embedding_lookup(embedding_matrix, sentence_ids)\n",
    "       \n",
    "    return cap_embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = model(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Data (incomplete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_ids = [line.strip() for line in open(\"id_data/train_ids.csv\", 'r')]\n",
    "filename = \"c3d_data/sub_activitynet_v1-3.c3d.hdf5\"\n",
    "video_feature_representation = h5py.File(filename, 'r')\n",
    "train_ids = [\"v_--0edUL8zmA\",\"v_hHiPEAiYKv0\",\"v_u2uoYvo8J5s\",\"v_c_NlYvL96y0\",\"v_sJFgo9H6zNo\"]\n",
    "video_data = dict()\n",
    "for videoid in train_ids:\n",
    "    print(videoid)\n",
    "    proposals_df = pd.read_csv('prop_data/' + videoid + '.csv',sep=' ')\n",
    "    c3d_features = video_feature_representation[videoid]['c3d_features'].value\n",
    "    max_frames = c3d_features.shape[0]\n",
    "    print(max_frames)\n",
    "    \n",
    "    for i in range(proposals_df.shape[0]):\n",
    "        f_init = proposals_df[\"f-init\"][i]\n",
    "        f_end =  proposals_df[\"f-end\"][i]\n",
    "        if (f_init < max_frames) and (f_end > 0):\n",
    "            if f_init < 0:\n",
    "                f_init = 0\n",
    "            if f_end > max_frames:\n",
    "                f_end = max_frames\n",
    "        \n",
    "            #print((f_init,f_end))\n",
    "            #print(c3d_features[f_init:f_end,:].shape)\n",
    "            h = temporal_pooling(c3d_features[f_init:f_end,:], mode=\"max\")\n",
    "            if i == 0:\n",
    "                H = h\n",
    "            else:\n",
    "                H = np.column_stack((H,h))\n",
    "        else:\n",
    "            proposals_df.drop(proposals_df.index[i])\n",
    "    video_data[videoid] = H\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
