{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# As usual, a bit of setup\n",
    "import time\n",
    "from time import process_time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import LOUPE.WILLOW.loupe as lp\n",
    "import tensorflow as tf\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import csv\n",
    "import copy\n",
    "import math\n",
    "from utils.data_utils import *\n",
    "import sys\n",
    "import re\n",
    "from utils.spj import Config\n",
    "from utils.spj import SPJ\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_c3d_features:  500\n",
      "num_proposals:  30\n",
      "num_classes:  1048\n",
      "num_classes:  1048\n",
      "num_steps:  50\n",
      "hidden_dim:  512\n",
      "batch_size:  9\n",
      "layers:  2\n",
      "eps:  1e-10\n"
     ]
    }
   ],
   "source": [
    "config = Config()\n",
    "print(\"num_c3d_features: \", config.num_c3d_features)\n",
    "print(\"num_proposals: \", config.num_proposals)\n",
    "print(\"num_classes: \", config.num_classes)\n",
    "print(\"num_classes: \", config.num_classes)\n",
    "print(\"num_steps: \", config.num_steps)\n",
    "print(\"hidden_dim: \", config.hidden_dim)\n",
    "print(\"batch_size: \", config.batch_size)\n",
    "print(\"layers: \", config.num_layers)\n",
    "print(\"eps: \", config.eps)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load small training data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of examples:  99\n",
      "train_data.shape:  (590, 508)\n",
      "padded_proposals.shape:  (99, 500, 30)\n",
      "padded_framestamps.shape:  (99, 2, 30)\n"
     ]
    }
   ],
   "source": [
    "train_ids,train_data,padded_proposals,padded_framestamps = video_preprocess()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get word2id in sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words in all captions:  504895\n",
      "Vocabulary Size (Unique):  13001\n",
      "all_padded_sentences_2.shape:  (99, 51, 30)\n"
     ]
    }
   ],
   "source": [
    "embedding_size =512\n",
    "vocabulary,vocab_size = caption_preprocess()\n",
    "emb_matrix,word2id,id2word = get_wordvector(embedding_size,vocab_size,vocabulary)\n",
    "pad_len = 50\n",
    "all_padded_sentences,all_padded_sentences_2,all_padded_sentences_id = get_padded_sentences_id(pad_len,train_ids, train_data, word2id)     \n",
    "print(\"all_padded_sentences_2.shape: \", all_padded_sentences_2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "config = Config()\n",
    "model = SPJ(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(H_train, Ipast_train, Ifuture_train, Ycaptions_train, Xcaptions_train,word2id_len,learning_rate, num_epochs = 5, minibatch_size = 9, print_cost = True,num_layers = 2,hidden_dim = 512):\n",
    "    \"\"\"\n",
    "    Implements a tensorflow neural network: C3D->DAPS->ATTENTION->CAPTIONING\n",
    "    \n",
    "    Arguments:\n",
    "    H_train -- training set, of shape = [n_train,num_c3d_features,num_proposals]\n",
    "    Y_train -- caption labels, of shape = [n_train,num_proposals,num_steps+1]\n",
    "    H_test -- training set, of shape = [n_test,num_c3d_features,num_proposals]\n",
    "    Y_test -- caption labels, of shape = [n_test,num_proposals,num_steps+1]\n",
    "    learning_rate -- learning rate of the optimization\n",
    "    num_epochs -- number of epochs of the optimization loop\n",
    "    minibatch_size -- size of a minibatch\n",
    "    print_cost -- True to print the cost every 100 epochs\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "    checkpoint_dir = \"/home/martnzjulio_a/checkpoints/\"\n",
    "    \n",
    "    batch_size = minibatch_size\n",
    "    \n",
    "    # to be able to rerun the model without overwriting tf variables\n",
    "    tf.reset_default_graph()    \n",
    "    \n",
    "    # to keep consistent results\n",
    "    tf.set_random_seed(1)                             \n",
    "    seed = 3                                         \n",
    "    \n",
    "    # size values\n",
    "    (n_train,num_c3d_features,num_proposals) = H_train.shape                        \n",
    "    (_,_,num_steps) = Xcaptions_train.shape\n",
    "    num_classes = word2id_len\n",
    "    \n",
    "    #print(\"n_train \", n_train)\n",
    "    #print(\"num_c3d_features \", num_c3d_features)\n",
    "    #print(\"num_proposals: \", num_proposals)\n",
    "    #print(\"num_steps: \", num_steps)\n",
    "    \n",
    "    # to keep track of costs\n",
    "    costs = []\n",
    "    \n",
    "    # keep track of global epoch number\n",
    "    global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "    \n",
    "    # create placeholders\n",
    "    H = tf.placeholder(tf.float32,shape=[batch_size, num_c3d_features, num_proposals], name=\"H\")\n",
    "    Ipast = tf.placeholder(tf.float32, shape=[batch_size, num_proposals, num_proposals], name=\"Ipast\")\n",
    "    Ifuture = tf.placeholder(tf.float32, shape=[batch_size, num_proposals, num_proposals], name=\"Ifuture\")\n",
    "    x = tf.placeholder(tf.int32, [batch_size, num_proposals, num_steps], name=\"x\")\n",
    "    y = tf.placeholder(tf.int32, [batch_size, num_proposals, num_steps+1], name=\"y\")\n",
    "    \n",
    "    # Model\n",
    "    config = Config()\n",
    "    spj = SPJ(config)\n",
    "    \n",
    "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer.\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(spj.loss, global_step=global_step)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Initialize all the variables\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    # Add ops to save and restore all the variables.\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    # Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:\n",
    "           \n",
    "        # check for latest checkpoint\n",
    "        latest_checkpoint = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "        if latest_checkpoint == None:\n",
    "            # If no check point run the initialization\n",
    "            print(\"No checkpint exists, initializing parameters...\")\n",
    "            sess.run(init)\n",
    "        else:\n",
    "            print(\"Restoring from latest checkpoint...\")\n",
    "            saver.restore(sess, latest_checkpoint)\n",
    "        \n",
    "        # Do the training loop\n",
    "        start = process_time()\n",
    "        for epoch in range(num_epochs):\n",
    "            #print(\"epoch: \", epoch)\n",
    "\n",
    "            epoch_cost = 0.                       # Defines a cost related to an epoch\n",
    "            num_minibatches = int(n_train / config.batch_size) # number of minibatches of size minibatch_size in the train set\n",
    "            seed = seed + 1\n",
    "            minibatches = random_mini_batches(H_train, Ipast_train, Ifuture_train, Ycaptions_train, Xcaptions_train, minibatch_size, seed = 0)\n",
    "\n",
    "            for counter,minibatch in enumerate(minibatches):\n",
    "                #print(\"counter: \", counter)\n",
    "\n",
    "                # Select a minibatch\n",
    "                (minibatch_H, minibatch_Ipast, minibatch_Ifuture, minibatch_Ycaptions, minibatch_Xcaptions) = minibatch\n",
    "                #print(\"minibatch_H.shape: \", minibatch_H.shape)\n",
    "                #print(\"minibatch_Ipast.shape: \", minibatch_Ipast.shape)\n",
    "                #print(\"minibatch_Ifuture.shape: \", minibatch_Ifuture.shape)\n",
    "                #print(\"minibatch_Ycaptions.shape: \", minibatch_Ycaptions.shape)\n",
    "                #print(\"minibatch_Xcaptions.shape: \", minibatch_Xcaptions.shape)\n",
    "                \n",
    "                # The line that runs the graph on a minibatch.\n",
    "                _ , minibatch_cost = sess.run([optimizer, spj.loss], feed_dict={spj._H: minibatch_H, spj._Ipast: minibatch_Ipast, spj._Ifuture: minibatch_Ifuture, spj._x: minibatch_Xcaptions, spj._y: minibatch_Ycaptions})\n",
    "\n",
    "                epoch_cost += minibatch_cost / num_minibatches\n",
    "                \n",
    "            # print cost every epoch\n",
    "            if print_cost == True:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "                costs.append(epoch_cost)\n",
    "            \n",
    "            # We save our model\n",
    "            if epoch % 20 == 0:\n",
    "                saver.save(sess, checkpoint_dir + 'model', global_step = global_step) # write_meta_graph=False\n",
    "                    \n",
    "        end = process_time()   \n",
    "        print(\"time elapased: \", end - start)\n",
    "        print()\n",
    "        # plot the cost\n",
    "        final_costs = np.squeeze(costs)\n",
    "        plt.plot(final_costs)\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # lets save the parameters in a variable\n",
    "        #parameters = sess.run(parameters)\n",
    "        #print (\"Parameters have been trained!\")\n",
    "\n",
    "        # Calculate the correct predictions\n",
    "        #correct_prediction = tf.equal(tf.argmax(Z3), tf.argmax(Y))\n",
    "\n",
    "        # Calculate accuracy on the test set\n",
    "        #accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "        #print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n",
    "        #print (\"Test Accuracy:\", accuracy.eval({X: X_test, Y: Y_test}))\n",
    "        \n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No checkpint exists, initializing parameters...\n",
      "Cost after epoch 0: nan\n",
      "Cost after epoch 1: nan\n",
      "Cost after epoch 2: nan\n",
      "Cost after epoch 3: nan\n",
      "Cost after epoch 4: nan\n",
      "time elapased:  20.391663349\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f011c800be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Case\n",
    "\n",
    "# input features\n",
    "H = padded_proposals.astype(np.float32)\n",
    "\n",
    "# input framstamps [f_init, f_end]\n",
    "framestamps = padded_framestamps\n",
    "\n",
    "# Indicators for past and future\n",
    "Ipast = temporal_indicator(framestamps, mode=\"past\").astype(np.float32)\n",
    "Ifuture = temporal_indicator(framestamps, mode=\"future\").astype(np.float32)\n",
    "\n",
    "# Word Embedding Matrix\n",
    "emb_matrix, word2id, id2word = get_wordvector(embedding_size,vocab_size,vocabulary) #changed by Songze\n",
    "\n",
    "sentence_ids = all_padded_sentences_id\n",
    "Ycaptions = copy.deepcopy(all_padded_sentences_2) \n",
    "Xcaptions = copy.deepcopy(all_padded_sentences)\n",
    "Xcaptions = np.transpose(Xcaptions,axes=(0,2,1)).astype(np.int32)\n",
    "Ycaptions = np.transpose(Ycaptions,axes=(0,2,1)).astype(np.int32)\n",
    "\n",
    "learning_rate = 0.001\n",
    "num_epochs = 5\n",
    "model(H, Ipast, Ifuture, Ycaptions, Xcaptions,len(word2id), learning_rate, num_epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
