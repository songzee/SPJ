{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shared/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "# As usual, a bit of setup\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import LOUPE.WILLOW.loupe as lp\n",
    "import tensorflow as tf\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import csv\n",
    "import copy\n",
    "import math\n",
    "from utils.data_utils import temporal_indicator\n",
    "from utils.data_utils import temporal_pooling\n",
    "from utils.data_utils import export_vocabulary\n",
    "import sys\n",
    "import re\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load small training data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of examples:  99\n",
      "train_data.shape:  (590, 508)\n",
      "padded_proposals.shape:  (99, 500, 30)\n",
      "padded_framestamps.shape:  (99, 2, 30)\n"
     ]
    }
   ],
   "source": [
    "def video_preprocess():\n",
    "    # format\n",
    "    train_data = pd.read_csv(\"train_extreme_small.csv\")\n",
    "    train_data.rename( columns={'Unnamed: 0':'index'}, inplace=True )\n",
    "    train_data[\"duration\"] = train_data[\"duration\"].astype('float32')\n",
    "    train_data[\"t_init\"], train_data[\"t_end\"] = train_data[\"timestamps\"].str.split(\", \", 1).str\n",
    "    train_data[\"t_init\"] = train_data[\"t_init\"].str.strip(\"[\")\n",
    "    train_data[\"t_end\"] = train_data[\"t_end\"].str.strip(\"]\")\n",
    "    train_data[\"t_init\"] = train_data[\"t_init\"].astype('float32')\n",
    "    train_data[\"t_end\"] = train_data[\"t_end\"].astype('float32')\n",
    "    train_data = train_data.drop('timestamps', 1)\n",
    "\n",
    "    # pool\n",
    "    filename = \"/home/songzeli/Data/sub_activitynet_v1-3.c3d.hdf5\"\n",
    "    video_feature_representation = h5py.File(filename, 'r')\n",
    "    train_ids = train_data['id'].unique()\n",
    "    f_inits = []\n",
    "    f_ends = []\n",
    "    max_pooled_representations = []\n",
    "    max_proposals = 0\n",
    "    padded_proposals = np.zeros((99,500,30))\n",
    "    padded_framestamps = -1*np.ones((99,2,30))\n",
    "    for v,video_id in enumerate(train_ids):\n",
    "        #print(\"video id: \", video_id)\n",
    "        temp = train_data[train_data['id']==video_id].reset_index()\n",
    "        C3D_features = video_feature_representation[\"v_QOlSCBRmfWY\"]['c3d_features'].value\n",
    "\n",
    "        if max_proposals < temp.shape[0]:\n",
    "            max_proposals = temp.shape[0]\n",
    "\n",
    "        for i in range(temp.shape[0]):\n",
    "\n",
    "            # get time info\n",
    "            duration = temp[\"duration\"][i]\n",
    "            t_init = temp[\"t_init\"][i]\n",
    "            t_end = temp[\"t_end\"][i]\n",
    "            num_frames = C3D_features.shape[0]\n",
    "\n",
    "            # compute start and end frame\n",
    "            f_init = int(round((t_init/duration)*num_frames))\n",
    "            f_end = int(round((t_end/duration)*num_frames))\n",
    "            #print(\"f_init: \", f_init, \"t_init: \", t_init)\n",
    "            #print(\"f_end: \", f_end, \"t_end: \", t_end)\n",
    "\n",
    "            # get max pool\n",
    "            if f_init <= f_end:\n",
    "                max_pooled_rep = temporal_pooling(C3D_features[f_init:f_end],\"max\")\n",
    "            else:\n",
    "                max_pooled_rep = temporal_pooling(C3D_features[f_end:f_init],\"max\")\n",
    "\n",
    "            # append info\n",
    "            f_inits.append(f_init)\n",
    "            f_ends.append(f_end)\n",
    "            max_pooled_representations.append(max_pooled_rep)\n",
    "            padded_proposals[v,:,i] = max_pooled_rep\n",
    "            padded_framestamps[v,0,i] = f_init\n",
    "            padded_framestamps[v,1,i] = f_end\n",
    "\n",
    "\n",
    "    f_inits = np.array(f_inits)\n",
    "    f_inits = pd.DataFrame({'f_init': f_inits})\n",
    "    f_ends = np.array(f_ends) \n",
    "    f_ends = pd.DataFrame({'f_end': f_ends})\n",
    "\n",
    "    max_pooled_representations = np.array(max_pooled_representations)\n",
    "    C3D_feature_column_names = [\"h\" + str(i) for i in range(max_pooled_representations.shape[1])] \n",
    "    max_pooled_representations = pd.DataFrame(max_pooled_representations, columns=C3D_feature_column_names)\n",
    "\n",
    "    train_data = pd.concat([train_data, f_inits, f_ends, max_pooled_representations], axis=1)\n",
    "    train_data.to_pickle(\"train_data\")\n",
    "\n",
    "    print(\"number of examples: \", train_ids.shape[0])\n",
    "    print(\"train_data.shape: \", train_data.shape)\n",
    "    print(\"padded_proposals.shape: \", padded_proposals.shape)\n",
    "    print(\"padded_framestamps.shape: \", padded_framestamps.shape) \n",
    "    return train_ids,train_data,padded_proposals,padded_framestamps\n",
    "    \n",
    "train_ids,train_data,padded_proposals,padded_framestamps = video_preprocess()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get word2id in sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "_PAD = b\"<pad>\"\n",
    "_UNK = b\"<unk>\"\n",
    "_STA = b\"<sta>\"\n",
    "_END = b\"<end>\"\n",
    "_START_VOCAB = [_PAD,_UNK,_STA,_END]\n",
    "PAD_ID = 0\n",
    "UNK_ID = 1\n",
    "STA_ID = 2\n",
    "END_ID = 3\n",
    "\n",
    "def caption_preprocess():\n",
    "\n",
    "    \n",
    "    train_voc = pd.read_csv(\"train_all.csv\")\n",
    "    train_voc.rename( columns={'Unnamed: 0':'index'}, inplace=True )\n",
    "    train_voc[\"duration\"] = train_voc[\"duration\"].astype('float32')\n",
    "    train_voc[\"t_init\"], train_voc[\"t_end\"] = train_voc[\"timestamps\"].str.split(\", \", 1).str\n",
    "    train_voc[\"t_init\"] = train_voc[\"t_init\"].str.strip(\"[\")\n",
    "    train_voc[\"t_end\"] = train_voc[\"t_end\"].str.strip(\"]\")\n",
    "    train_voc[\"t_init\"] = train_voc[\"t_init\"].astype('float32')\n",
    "    train_voc[\"t_end\"] = train_voc[\"t_end\"].astype('float32')\n",
    "    train_voc = train_voc.drop('timestamps', 1)\n",
    "\n",
    "    export_vocabulary(train_voc)\n",
    "    df = pd.read_csv('vocabulary.csv')\n",
    "    voc = df[\"Unnamed: 0\"].tolist()\n",
    "    vocabulary = []\n",
    "    for word in voc:\n",
    "        if word.isalpha():\n",
    "            vocabulary.append(word)\n",
    "            \n",
    "    vocab_size = len(vocabulary)\n",
    "    return vocabulary,vocab_size\n",
    "    \n",
    "\n",
    "def get_wordvector(emb_dim,vocab_size,vocabulary):\n",
    "    \"\"\"Reads from original word lib file and returns embedding matrix and\n",
    "    mappings from words to word ids.\n",
    "\n",
    "    Returns:\n",
    "      emb_matrix: Numpy array shape (len(vocabulary), word_dim) containing word embeddings\n",
    "        (plus PAD and UNK embeddings in first 4 rows).\n",
    "        The rows of emb_matrix correspond to the word ids given in word2id and id2word\n",
    "      word2id: dictionary mapping word (string) to word id (int)\n",
    "      id2word: dictionary mapping word id (int) to word (string)\n",
    "    \"\"\"\n",
    "    \n",
    "    vocabulary = _START_VOCAB + vocabulary\n",
    "\n",
    "    emb_matrix = np.zeros((vocab_size + len(_START_VOCAB), emb_dim))\n",
    "    word2id = {}\n",
    "    id2word = {}\n",
    "\n",
    "    random_init = True\n",
    "    # randomly initialize all the tokens\n",
    "    emb_matrix[:, :] = np.random.randn(vocab_size + len(_START_VOCAB), emb_dim)\n",
    "\n",
    "    # put start tokens in the dictionaries\n",
    "    idx = 0\n",
    "    for word in vocabulary:\n",
    "        word2id[word] = idx\n",
    "        id2word[idx] = word\n",
    "        idx += 1\n",
    "\n",
    "\n",
    "    final_vocab_size = vocab_size + len(_START_VOCAB)\n",
    "    assert len(word2id) == final_vocab_size\n",
    "    assert len(id2word) == final_vocab_size\n",
    "    assert idx == final_vocab_size\n",
    "\n",
    "    return emb_matrix, word2id, id2word\n",
    "#Changed by Songze\n",
    "def split_by_whitespace(sentence):\n",
    "    words = []\n",
    "    for space_separated_fragment in sentence.strip().split():\n",
    "        words.extend(re.split(\" \", space_separated_fragment))\n",
    "    return [w for w in words if w]\n",
    "\n",
    "\n",
    "def intstr_to_intlist(string):\n",
    "    \"\"\"Given a string e.g. '311 9 1334 635 6192 56 639', returns as a list of integers\"\"\"\n",
    "    return [int(s) for s in string.split()]\n",
    "\n",
    "\n",
    "def sentence_to_token_ids(sentence, word2id):\n",
    "    \"\"\"Turns an already-tokenized sentence string into word indices\n",
    "    e.g. \"i do n't know\" -> [9, 32, 16, 96]\n",
    "    Note any token that isn't in the word2id mapping gets mapped to the id for UNK\n",
    "    \"\"\"\n",
    "    tokens = split_by_whitespace(sentence) # list of strings\n",
    "    ids = [word2id.get(w.lower(), UNK_ID) for w in tokens]\n",
    "    return tokens, ids\n",
    "\n",
    "\n",
    "def padded(token_batch, batch_pad=0):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "      token_batch: List (length batch size) of lists of ints.\n",
    "      batch_pad: Int. Length to pad to. If 0, pad to maximum length sequence in token_batch.\n",
    "    Returns:\n",
    "      List (length batch_size) of padded lists of ints.\n",
    "        All are same length - batch_pad if batch_pad!=0, otherwise the maximum length in token_batch\n",
    "    \"\"\"\n",
    "    maxlen = max(lambda x: len(x), token_batch) if batch_pad == 0 else batch_pad\n",
    "    res = [STA_ID]+token_batch+[END_ID]+[PAD_ID] * (maxlen - len(token_batch)-2)\n",
    "\n",
    "    return res\n",
    "\n",
    "def get_padded_sentences_id(pad_len,train_ids):\n",
    "    all_padded_sentences = np.zeros((99,pad_len,30))\n",
    "    for v,video_id in enumerate(train_ids):\n",
    "        temp = train_data[train_data['id']==video_id].reset_index()\n",
    "        for i in range(temp.shape[0]):\n",
    "            words,ids = sentence_to_token_ids(temp['sentences'][i][:-1],word2id)\n",
    "            ids_pad = padded(ids,pad_len)\n",
    "            all_padded_sentences[v,:,i] = ids_pad\n",
    "\n",
    "\n",
    "    all_padded_sentences_2 = np.zeros((99,pad_len+1,30))\n",
    "    for v,video_id in enumerate(train_ids):\n",
    "        temp = train_data[train_data['id']==video_id].reset_index()\n",
    "        for i in range(temp.shape[0]):\n",
    "            words,ids = sentence_to_token_ids(temp['sentences'][i][:-1],word2id)\n",
    "            ids_pad = padded(ids,pad_len+1)\n",
    "            all_padded_sentences_2[v,:,i] = ids_pad\n",
    "    all_padded_sentences_id = np.array(all_padded_sentences).astype(int)\n",
    "            \n",
    "    return all_padded_sentences,all_padded_sentences_2,all_padded_sentences_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words in all captions:  504895\n",
      "Vocabulary Size (Unique):  13001\n",
      "all_padded_sentences_2.shape:  (99, 51, 30)\n"
     ]
    }
   ],
   "source": [
    "embedding_size =512\n",
    "vocabulary,vocab_size = caption_preprocess()\n",
    "emb_matrix,word2id,id2word = get_wordvector(embedding_size,vocab_size,vocabulary)\n",
    "pad_len = 50\n",
    "all_padded_sentences,all_padded_sentences_2,all_padded_sentences_id = get_padded_sentences_id(pad_len,train_ids)     \n",
    "print(\"all_padded_sentences_2.shape: \", all_padded_sentences_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_module(H, Ipast, Ifuture, num_proposals, num_c3d_features, num_steps, batch_size,eps = 1e-10):\n",
    "    \"\"\"\n",
    "    Implements the attention module: see https://cs.stanford.edu/people/ranjaykrishna/densevid/\n",
    "    \n",
    "    Arguments:\n",
    "    H -- input dataset placeholder, of shape = [None, N, K] and dtype \"float\"\n",
    "    Ipast -- placeholder for the indicators of past, shape = [None, K, K] and dtype \"float\"\n",
    "    Ifuture == placeholder for the indicators of future, shape = [None, K, K] and dtype \"float\"\n",
    "    parameters -- python dictionary containing your parameters \"Wa\", \"ba\", sapes [N,N] and [N,1] respectively\n",
    "\n",
    "    Returns:\n",
    "    Hout -- concatenated output (hpast, h, hfuture), shape = [batch_size, 3*num_c3d_features, num_proposals]\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"H dtype: \", H.dtype)\n",
    "    print(\"Ipast dtype: \", Ipast.dtype)\n",
    "    print(\"Ifuture dtype: \", Ifuture.dtype)\n",
    "    #print(\"x dtype: \", x.dtype)\n",
    "    #print(\"y dtype: \", y.dtype)\n",
    "    \n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    Wa = tf.get_variable(\"Wa\", [num_c3d_features,num_c3d_features], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    ba = tf.get_variable(\"ba\", [num_c3d_features,1], initializer = tf.zeros_initializer())\n",
    "\n",
    "    # forward pass\n",
    "    W = tf.transpose(tf.tensordot(Wa,tf.transpose(H,perm=[1,2,0]),axes=[[1], [0]]),perm=[2,0,1]) + ba # shape: [None,num_proposals,num_proposals]\n",
    "    A = tf.matmul(tf.transpose(W,perm=[0,2,1]),H) # shape: [None,num_proposals,num_proposals]\n",
    "    A_flat = tf.reshape(A, [-1, num_proposals*num_proposals]) # shape: [None,num_proposals*num_proposals]\n",
    "\n",
    "    # future features\n",
    "    Ifuture_flat = tf.reshape(Ifuture, [-1, num_proposals*num_proposals]) # shape: [None,K*K]\n",
    "    Afuture = tf.reshape(tf.multiply(Ifuture_flat,A_flat),[-1,num_proposals,num_proposals]) # shape: [None,K,K]\n",
    "    Zfuture = tf.reduce_sum(Ifuture,axis=2)+eps # shape: [None,num_proposals]\n",
    "    Hfuture = tf.transpose(tf.transpose(tf.matmul(H,tf.transpose(Afuture,perm=[0,2,1])),perm=[1,0,2])/Zfuture,perm=[1,0,2]) # shape: [None,num_c3d_features,num_proposals]\n",
    "\n",
    "    # past features\n",
    "    Ipast_flat = tf.reshape(Ipast, [-1, num_proposals*num_proposals]) # shape: [None,num_proposals*num_proposals]\n",
    "    Apast = tf.reshape(tf.multiply(Ipast_flat,A_flat),[-1,num_proposals,num_proposals]) # shape: [None,num_proposals,num_proposals]\n",
    "    Zpast = tf.reduce_sum(Ipast,axis=2)+eps # shape: [None,num_proposals]\n",
    "    Hpast = tf.transpose(tf.transpose(tf.matmul(H,tf.transpose(Apast,perm=[0,2,1])),perm=[1,0,2])/Zfuture,perm=[1,0,2]) # shape: [None,num_c3d_features,num_proposals]\n",
    "\n",
    "    # stacked features\n",
    "    Hout = tf.concat([Hpast, H, Hfuture], 1)\n",
    "\n",
    "    print(\"Hfuture shape: \", Hfuture.get_shape().as_list())\n",
    "    print(\"W shape: \", W.get_shape().as_list())\n",
    "    print(\"A shape: \", A.get_shape().as_list())\n",
    "    print(\"A_flat shape: \", A_flat.get_shape().as_list())\n",
    "    print(\"Ifuture_flat shape: \", Ifuture_flat.get_shape().as_list())\n",
    "    print(\"Zfuture: \", Zfuture.get_shape().as_list())\n",
    "    print(\"Hfuture: \", Hfuture.get_shape().as_list())\n",
    "    print(\"Hpast: \", Hfuture.get_shape().as_list())\n",
    "    print(\"Hout: \", Hout.get_shape().as_list())\n",
    "    \n",
    "    return Hout\n",
    "\n",
    "def language_module(Hout, x, num_classes, hidden_dim, num_steps, num_proposals, num_layers, batch_size):\n",
    "    '''\n",
    "    Inputs: \n",
    "      number of classes\n",
    "      hidden_dim = number units in lstm and word embedding\n",
    "      num_steps, length of captions\n",
    "      num_steps\n",
    "      num_layers \n",
    "      batch_size\n",
    "    '''\n",
    "    \n",
    "    Hout = tf.transpose(Hout, perm=[0,2,1])\n",
    "    Hout = tf.reshape(Hout, [-1, 1500])\n",
    "    \n",
    "    # create placeholder\n",
    "    #x_captions = tf.placeholder(tf.int32, [batch_size, num_proposals, num_steps], name=\"x_captions\")\n",
    "    \n",
    "    \n",
    "    feature_inputs = tf.expand_dims(tf.layers.dense(inputs=Hout,units=hidden_dim,activation=tf.nn.relu),1)\n",
    "    print(\"feature_inputs.shape: \",feature_inputs.get_shape().as_list())\n",
    "\n",
    "    embeddings = tf.get_variable('embedding_matrix', [num_classes, hidden_dim])\n",
    "    embedding_inputs = tf.nn.embedding_lookup(embeddings, tf.reshape(x,[-1,num_steps]))\n",
    "    print(\"embedding_inputs.shape: \",embedding_inputs.get_shape().as_list())\n",
    "                                              \n",
    "    lstm_inputs = tf.concat(values=[feature_inputs, embedding_inputs],axis=1)\n",
    "    print(\"all_inputs.shape: \", lstm_inputs.get_shape().as_list())                                      \n",
    "    \n",
    "    lstm_cell = tf.nn.rnn_cell.LSTMCell(num_units=hidden_dim,state_is_tuple=True)\n",
    "    lstm_cells = tf.nn.rnn_cell.MultiRNNCell([lstm_cell] * num_layers, state_is_tuple=True)\n",
    "    initial_state = lstm_cells.zero_state(batch_size*num_proposals, tf.float32)\n",
    "    lstm_outputs, final_state = tf.nn.dynamic_rnn(cell=lstm_cells,inputs=lstm_inputs,initial_state=initial_state)\n",
    "    print(\"lstm_outputs.shape: \", lstm_outputs.get_shape().as_list())                                         \n",
    "                                              \n",
    "    logits = tf.layers.dense(inputs=tf.reshape(lstm_outputs,[-1,hidden_dim]),units=num_classes)\n",
    "                                         \n",
    "    predictions = tf.argmax(logits,1)\n",
    "    predictions = tf.reshape(predictions, [batch_size,num_proposals,num_steps+1])\n",
    "    print(\"predictions.shape: \", predictions.get_shape().as_list())\n",
    "    \n",
    "    logits = tf.reshape(logits, [batch_size,num_proposals,num_steps+1,num_classes])\n",
    "    print(\"logits.shape: \", logits.get_shape().as_list())\n",
    "                                                                            \n",
    "    return predictions, logits\n",
    "\n",
    "def caption_cost(y, logits, num_classes, num_proposals,num_steps,batch_size):\n",
    "    print(\"y_captions.shape: \", y.get_shape().as_list())\n",
    "    print()\n",
    "    loss = tf.reduce_sum(\n",
    "        tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "            logits=tf.reshape(logits,[-1,num_classes]), \n",
    "            labels=tf.reshape(y,[-1])\n",
    "        )\n",
    "    )\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Forward Pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H dtype:  <dtype: 'float32'>\n",
      "Ipast dtype:  <dtype: 'float32'>\n",
      "Ifuture dtype:  <dtype: 'float32'>\n",
      "Hfuture shape:  [9, 500, 30]\n",
      "W shape:  [9, 500, 30]\n",
      "A shape:  [9, 30, 30]\n",
      "A_flat shape:  [9, 900]\n",
      "Ifuture_flat shape:  [9, 900]\n",
      "Zfuture:  [9, 30]\n",
      "Hfuture:  [9, 500, 30]\n",
      "Hpast:  [9, 500, 30]\n",
      "Hout:  [9, 1500, 30]\n",
      "feature_inputs.shape:  [270, 1, 512]\n",
      "embedding_inputs.shape:  [270, 50, 512]\n",
      "all_inputs.shape:  [270, 51, 512]\n",
      "lstm_outputs.shape:  [270, 51, 512]\n",
      "predictions.shape:  [9, 30, 51]\n",
      "logits.shape:  [9, 30, 51, 10194]\n",
      "y_captions.shape:  [9, 30, 51]\n",
      "\n",
      "10194\n"
     ]
    }
   ],
   "source": [
    "H_train = padded_proposals.astype(np.float32)\n",
    "framestamps = padded_framestamps\n",
    "Ipast = temporal_indicator(framestamps, mode=\"past\")\n",
    "Ipast_train = Ipast.astype(np.float32)\n",
    "Ifuture = temporal_indicator(framestamps, mode=\"future\")\n",
    "Ifuture_train = Ifuture.astype(np.float32)\n",
    "emb_matrix, word2id, id2word = get_wordvector(embedding_size,vocab_size,vocabulary) #changed by Songze\n",
    "sentence_ids = all_padded_sentences_id\n",
    "Ycaptions = copy.deepcopy(all_padded_sentences_2) # holds i\n",
    "Xcaptions = copy.deepcopy(all_padded_sentences)\n",
    "Xcaptions = Xcaptions.astype(np.int32)\n",
    "Ycaptions = Ycaptions.astype(np.int32)\n",
    "Xcaptions_train = np.transpose(Xcaptions,axes=(0,2,1))\n",
    "Ycaptions_train = np.transpose(Ycaptions,axes=(0,2,1))\n",
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "num_c3d_features = 500\n",
    "num_classes = len(word2id)\n",
    "\n",
    "hidden_dim = 512\n",
    "num_steps = 50\n",
    "num_proposals = 30\n",
    "num_layers = 2\n",
    "batch_size = 9\n",
    "\n",
    "tf.reset_default_graph()\n",
    "# create placeholders\n",
    "H = tf.placeholder(tf.float32,shape=[batch_size, num_c3d_features, num_proposals], name=\"H\")\n",
    "Ipast = tf.placeholder(tf.float32, shape=[batch_size, num_proposals, num_proposals], name=\"Ipast\")\n",
    "Ifuture = tf.placeholder(tf.float32, shape=[batch_size, num_proposals, num_proposals], name=\"Ifuture\")\n",
    "x = tf.placeholder(tf.int32, [batch_size, num_proposals, num_steps], name=\"x\")\n",
    "y = tf.placeholder(tf.int32, [batch_size, num_proposals, num_steps+1], name=\"y\")\n",
    "\n",
    "# forward pass\n",
    "Hout = attention_module(H, Ipast, Ifuture, num_proposals, num_c3d_features, num_steps, batch_size)\n",
    "predictions, logits = language_module(Hout, x, num_classes, hidden_dim, num_steps, num_proposals, num_layers, batch_size)\n",
    "cap_loss = caption_cost(y, logits, num_classes, num_proposals,num_steps,batch_size)\n",
    "\n",
    "\n",
    "# check forward pass\n",
    "#with tf.Session() as sess:\n",
    "#    # Run the initialization\n",
    "#    sess.run(init)\n",
    "#    minibatch_cost = sess.run([cap_loss], feed_dict={H: H_train[0:batch_size], Ipast: Ipast_train[0:batch_size], Ifuture: Ifuture_train[0:batch_size], x: Xcaptions_train[0:batch_size], y: Ycaptions_train[0:batch_size]})\n",
    "\n",
    "print(len(word2id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(H_train, Ipast_train, Ifuture_train, Ycaptions_train, Xcaptions_train,word2id_len,learning_rate = 1e-6, num_epochs = 3, minibatch_size = 9, print_cost = True,num_layers = 2,hidden_dim = 512):\n",
    "    \"\"\"\n",
    "    Implements a tensorflow neural network: C3D->DAPS->ATTENTION->CAPTIONING\n",
    "    \n",
    "    Arguments:\n",
    "    H_train -- training set, of shape = [n_train,num_c3d_features,num_proposals]\n",
    "    Y_train -- caption labels, of shape = [n_train,num_proposals,num_steps+1]\n",
    "    H_test -- training set, of shape = [n_test,num_c3d_features,num_proposals]\n",
    "    Y_test -- caption labels, of shape = [n_test,num_proposals,num_steps+1]\n",
    "    learning_rate -- learning rate of the optimization\n",
    "    num_epochs -- number of epochs of the optimization loop\n",
    "    minibatch_size -- size of a minibatch\n",
    "    print_cost -- True to print the cost every 100 epochs\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "    batch_size = minibatch_size\n",
    "    \n",
    "    # to be able to rerun the model without overwriting tf variables\n",
    "    tf.reset_default_graph()    \n",
    "    \n",
    "    # to keep consistent results\n",
    "    tf.set_random_seed(1)                             \n",
    "    seed = 3                                         \n",
    "    \n",
    "    # size values\n",
    "    (n_train,num_c3d_features,num_proposals) = H_train.shape                        \n",
    "    (_,_,num_steps) = Xcaptions_train.shape\n",
    "    num_classes = word2id_len\n",
    "#     num_layers = 2\n",
    "#     hidden_dim = 512\n",
    "    \n",
    "    print(\"n_train \", n_train)\n",
    "    print(\"num_c3d_features \", num_c3d_features)\n",
    "    print(\"num_proposals: \", num_proposals)\n",
    "    print(\"num_steps: \", num_steps)\n",
    "    \n",
    "    # to keep track of costs\n",
    "    costs = []  \n",
    "    \n",
    "    # create placeholders\n",
    "    H = tf.placeholder(tf.float32,shape=[batch_size, num_c3d_features, num_proposals], name=\"H\")\n",
    "    Ipast = tf.placeholder(tf.float32, shape=[batch_size, num_proposals, num_proposals], name=\"Ipast\")\n",
    "    Ifuture = tf.placeholder(tf.float32, shape=[batch_size, num_proposals, num_proposals], name=\"Ifuture\")\n",
    "    x = tf.placeholder(tf.int32, [batch_size, num_proposals, num_steps], name=\"x\")\n",
    "    y = tf.placeholder(tf.int32, [batch_size, num_proposals, num_steps+1], name=\"y\")\n",
    "    \n",
    "    # attention module\n",
    "    #attention_module(K,N, batch_size)\n",
    "    Hout = attention_module(\n",
    "        H,\n",
    "        Ipast,\n",
    "        Ifuture,\n",
    "        num_proposals, \n",
    "        num_c3d_features,\n",
    "        num_steps,\n",
    "        batch_size\n",
    "    )\n",
    "    \n",
    "    # language module\n",
    "    #language_module(Hout, num_classes, hidden_dim, num_steps, num_proposals, num_layers, batch_size)\n",
    "    predictions, logits = language_module(\n",
    "        Hout, \n",
    "        x,\n",
    "        num_classes, \n",
    "        hidden_dim, \n",
    "        num_steps, \n",
    "        num_proposals, \n",
    "        num_layers, \n",
    "        batch_size\n",
    "    )\n",
    "    \n",
    "    # cost\n",
    "    # caption_cost(logits, num_classes, num_proposals,num_steps,batch_size)\n",
    "    cap_loss = caption_cost(\n",
    "        y,\n",
    "        logits, \n",
    "        num_classes, \n",
    "        num_proposals, \n",
    "        num_steps, \n",
    "        batch_size\n",
    "    )\n",
    "    \n",
    "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer.\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cap_loss)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Initialize all the variables\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "        \n",
    "        # Do the training loop\n",
    "        for epoch in range(num_epochs):\n",
    "            print(\"epoch: \", epoch)\n",
    "\n",
    "            epoch_cost = 0.                       # Defines a cost related to an epoch\n",
    "            num_minibatches = int(n_train / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "            seed = seed + 1\n",
    "            minibatches = random_mini_batches(H_train, Ipast_train, Ifuture_train, Ycaptions_train, Xcaptions_train, minibatch_size, seed = 0)\n",
    "\n",
    "            for counter,minibatch in enumerate(minibatches):\n",
    "                print(\"counter: \", counter)\n",
    "\n",
    "                # Select a minibatch\n",
    "                (minibatch_H, minibatch_Ipast, minibatch_Ifuture, minibatch_Ycaptions, minibatch_Xcaptions) = minibatch\n",
    "                print(\"minibatch_H.shape: \", minibatch_H.shape)\n",
    "                print(\"minibatch_Ipast.shape: \", minibatch_Ipast.shape)\n",
    "                print(\"minibatch_Ifuture.shape: \", minibatch_Ifuture.shape)\n",
    "                print(\"minibatch_Ycaptions.shape: \", minibatch_Ycaptions.shape)\n",
    "                print(\"minibatch_Xcaptions.shape: \", minibatch_Xcaptions.shape)\n",
    "                \n",
    "                print(type(minibatch_H))\n",
    "                print(type(minibatch_Ipast))\n",
    "                print(type(minibatch_Ifuture))\n",
    "                print(type(minibatch_Ycaptions))\n",
    "                print(type(minibatch_Xcaptions))\n",
    "                \n",
    "                # The line that runs the graph on a minibatch.\n",
    "                _ , minibatch_cost = sess.run([optimizer, cap_loss], feed_dict={H: minibatch_H, Ipast: minibatch_Ipast, Ifuture: minibatch_Ifuture, x: minibatch_Xcaptions, y: minibatch_Ycaptions})\n",
    "\n",
    "                epoch_cost += minibatch_cost / num_minibatches\n",
    "\n",
    "            # Print the cost every epoch\n",
    "            if print_cost == True and epoch % 2 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "                \n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # lets save the parameters in a variable\n",
    "        parameters = sess.run(parameters)\n",
    "        print (\"Parameters have been trained!\")\n",
    "\n",
    "        # Calculate the correct predictions\n",
    "        correct_prediction = tf.equal(tf.argmax(Z3), tf.argmax(Y))\n",
    "\n",
    "        # Calculate accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "        print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n",
    "        print (\"Test Accuracy:\", accuracy.eval({X: X_test, Y: Y_test}))\n",
    "        \n",
    "        return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_mini_batches(H, Ipast, Ifuture, Ycaptions, Xcaptions, mini_batch_size = 9, seed = 0):\n",
    "    \"\"\"\n",
    "    Creates a list of random minibatches from (H, Ipast, Ifuture, Ycaptions, Xcaptions)\n",
    "    \n",
    "    Arguments:\n",
    "    H -- training set, of shape = [n_train,num_c3d_features,num_proposals]\n",
    "    Y -- caption labels, of shape = [n_train,num_proposals,num_steps+1]\n",
    "    mini_batch_size - size of the mini-batches, integer\n",
    "    seed -- this is only for the purpose of grading, so that you're \"random minibatches are the same as ours.\n",
    "    \n",
    "    Returns:\n",
    "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    X -- input data, of shape (input size, number of examples)\n",
    "    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)\n",
    "    mini_batch_size - size of the mini-batches, integer\n",
    "    seed -- this is only for the purpose of grading, so that you're \"random minibatches are the same as ours.\n",
    "    \n",
    "    Returns:\n",
    "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
    "     \"\"\"\n",
    "    \n",
    "    m = H.shape[0]                  # number of training examples\n",
    "    mini_batches = []\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Step 1: Shuffle (H, Ipast, Ifuture, Ycaptions, Xcaptions)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_H = H[permutation]\n",
    "    shuffled_Ipast = Ipast[permutation]\n",
    "    shuffled_Ifuture = Ifuture[permutation]\n",
    "    shuffled_Ycaptions = Ycaptions[permutation]\n",
    "    shuffled_Xcaptions = Xcaptions[permutation]\n",
    "    \n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        mini_batch_H = shuffled_H[k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
    "        mini_batch_Ipast = shuffled_Ipast[k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
    "        mini_batch_Ifuture = shuffled_Ifuture[k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
    "        mini_batch_Ycaptions = shuffled_Ycaptions[k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
    "        mini_batch_Xcaptions = shuffled_Xcaptions[k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
    "        mini_batch = (mini_batch_H, mini_batch_Ipast, mini_batch_Ifuture, mini_batch_Ycaptions, mini_batch_Xcaptions)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        mini_batch_H = shuffled_H[num_complete_minibatches * mini_batch_size : m]\n",
    "        mini_batch_Ipast = shuffled_Ipast[num_complete_minibatches * mini_batch_size : m]\n",
    "        mini_batch_Ifuture = shuffled_Ifuture[num_complete_minibatches * mini_batch_size : m]\n",
    "        mini_batch_Ycaptions = shuffled_Ycaptions[num_complete_minibatches * mini_batch_size : m]\n",
    "        mini_batch_Xcaptions = shuffled_Xcaptions[num_complete_minibatches * mini_batch_size : m]\n",
    "        mini_batch = (mini_batch_H, mini_batch_Ipast, mini_batch_Ifuture, mini_batch_Ycaptions, mini_batch_Xcaptions)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int32\n",
      "H.shape:  (99, 500, 30)\n",
      "framestamps.shape:  (99, 2, 30)\n",
      "Ipast.shape:  (99, 30, 30)\n",
      "Ifuture.shape:  (99, 30, 30)\n",
      "Ycaptions.shape:  (99, 30, 51)\n",
      "Xcaptions.shape:  (99, 30, 50)\n",
      "n_train  99\n",
      "num_c3d_features  500\n",
      "num_proposals:  30\n",
      "num_steps:  50\n",
      "H dtype:  <dtype: 'float32'>\n",
      "Ipast dtype:  <dtype: 'float32'>\n",
      "Ifuture dtype:  <dtype: 'float32'>\n",
      "Hfuture shape:  [9, 500, 30]\n",
      "W shape:  [9, 500, 30]\n",
      "A shape:  [9, 30, 30]\n",
      "A_flat shape:  [9, 900]\n",
      "Ifuture_flat shape:  [9, 900]\n",
      "Zfuture:  [9, 30]\n",
      "Hfuture:  [9, 500, 30]\n",
      "Hpast:  [9, 500, 30]\n",
      "Hout:  [9, 1500, 30]\n",
      "feature_inputs.shape:  [270, 1, 512]\n",
      "embedding_inputs.shape:  [270, 50, 512]\n",
      "all_inputs.shape:  [270, 51, 512]\n",
      "lstm_outputs.shape:  [270, 51, 512]\n",
      "predictions.shape:  [9, 30, 51]\n",
      "logits.shape:  [9, 30, 51, 10194]\n",
      "y_captions.shape:  [9, 30, 51]\n",
      "\n",
      "epoch:  0\n",
      "counter:  0\n",
      "minibatch_H.shape:  (9, 500, 30)\n",
      "minibatch_Ipast.shape:  (9, 30, 30)\n",
      "minibatch_Ifuture.shape:  (9, 30, 30)\n",
      "minibatch_Ycaptions.shape:  (9, 30, 51)\n",
      "minibatch_Xcaptions.shape:  (9, 30, 50)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "counter:  1\n",
      "minibatch_H.shape:  (9, 500, 30)\n",
      "minibatch_Ipast.shape:  (9, 30, 30)\n",
      "minibatch_Ifuture.shape:  (9, 30, 30)\n",
      "minibatch_Ycaptions.shape:  (9, 30, 51)\n",
      "minibatch_Xcaptions.shape:  (9, 30, 50)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "counter:  2\n",
      "minibatch_H.shape:  (9, 500, 30)\n",
      "minibatch_Ipast.shape:  (9, 30, 30)\n",
      "minibatch_Ifuture.shape:  (9, 30, 30)\n",
      "minibatch_Ycaptions.shape:  (9, 30, 51)\n",
      "minibatch_Xcaptions.shape:  (9, 30, 50)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "counter:  3\n",
      "minibatch_H.shape:  (9, 500, 30)\n",
      "minibatch_Ipast.shape:  (9, 30, 30)\n",
      "minibatch_Ifuture.shape:  (9, 30, 30)\n",
      "minibatch_Ycaptions.shape:  (9, 30, 51)\n",
      "minibatch_Xcaptions.shape:  (9, 30, 50)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "counter:  4\n",
      "minibatch_H.shape:  (9, 500, 30)\n",
      "minibatch_Ipast.shape:  (9, 30, 30)\n",
      "minibatch_Ifuture.shape:  (9, 30, 30)\n",
      "minibatch_Ycaptions.shape:  (9, 30, 51)\n",
      "minibatch_Xcaptions.shape:  (9, 30, 50)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "counter:  5\n",
      "minibatch_H.shape:  (9, 500, 30)\n",
      "minibatch_Ipast.shape:  (9, 30, 30)\n",
      "minibatch_Ifuture.shape:  (9, 30, 30)\n",
      "minibatch_Ycaptions.shape:  (9, 30, 51)\n",
      "minibatch_Xcaptions.shape:  (9, 30, 50)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "counter:  6\n",
      "minibatch_H.shape:  (9, 500, 30)\n",
      "minibatch_Ipast.shape:  (9, 30, 30)\n",
      "minibatch_Ifuture.shape:  (9, 30, 30)\n",
      "minibatch_Ycaptions.shape:  (9, 30, 51)\n",
      "minibatch_Xcaptions.shape:  (9, 30, 50)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "counter:  7\n",
      "minibatch_H.shape:  (9, 500, 30)\n",
      "minibatch_Ipast.shape:  (9, 30, 30)\n",
      "minibatch_Ifuture.shape:  (9, 30, 30)\n",
      "minibatch_Ycaptions.shape:  (9, 30, 51)\n",
      "minibatch_Xcaptions.shape:  (9, 30, 50)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "counter:  8\n",
      "minibatch_H.shape:  (9, 500, 30)\n",
      "minibatch_Ipast.shape:  (9, 30, 30)\n",
      "minibatch_Ifuture.shape:  (9, 30, 30)\n",
      "minibatch_Ycaptions.shape:  (9, 30, 51)\n",
      "minibatch_Xcaptions.shape:  (9, 30, 50)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "counter:  9\n",
      "minibatch_H.shape:  (9, 500, 30)\n",
      "minibatch_Ipast.shape:  (9, 30, 30)\n",
      "minibatch_Ifuture.shape:  (9, 30, 30)\n",
      "minibatch_Ycaptions.shape:  (9, 30, 51)\n",
      "minibatch_Xcaptions.shape:  (9, 30, 50)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "counter:  10\n",
      "minibatch_H.shape:  (9, 500, 30)\n",
      "minibatch_Ipast.shape:  (9, 30, 30)\n",
      "minibatch_Ifuture.shape:  (9, 30, 30)\n",
      "minibatch_Ycaptions.shape:  (9, 30, 51)\n",
      "minibatch_Xcaptions.shape:  (9, 30, 50)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "Cost after epoch 0: 127081.278409\n",
      "epoch:  1\n",
      "counter:  0\n",
      "minibatch_H.shape:  (9, 500, 30)\n",
      "minibatch_Ipast.shape:  (9, 30, 30)\n",
      "minibatch_Ifuture.shape:  (9, 30, 30)\n",
      "minibatch_Ycaptions.shape:  (9, 30, 51)\n",
      "minibatch_Xcaptions.shape:  (9, 30, 50)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "counter:  1\n",
      "minibatch_H.shape:  (9, 500, 30)\n",
      "minibatch_Ipast.shape:  (9, 30, 30)\n",
      "minibatch_Ifuture.shape:  (9, 30, 30)\n",
      "minibatch_Ycaptions.shape:  (9, 30, 51)\n",
      "minibatch_Xcaptions.shape:  (9, 30, 50)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "counter:  2\n",
      "minibatch_H.shape:  (9, 500, 30)\n",
      "minibatch_Ipast.shape:  (9, 30, 30)\n",
      "minibatch_Ifuture.shape:  (9, 30, 30)\n",
      "minibatch_Ycaptions.shape:  (9, 30, 51)\n",
      "minibatch_Xcaptions.shape:  (9, 30, 50)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "counter:  3\n",
      "minibatch_H.shape:  (9, 500, 30)\n",
      "minibatch_Ipast.shape:  (9, 30, 30)\n",
      "minibatch_Ifuture.shape:  (9, 30, 30)\n",
      "minibatch_Ycaptions.shape:  (9, 30, 51)\n",
      "minibatch_Xcaptions.shape:  (9, 30, 50)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "counter:  4\n",
      "minibatch_H.shape:  (9, 500, 30)\n",
      "minibatch_Ipast.shape:  (9, 30, 30)\n",
      "minibatch_Ifuture.shape:  (9, 30, 30)\n",
      "minibatch_Ycaptions.shape:  (9, 30, 51)\n",
      "minibatch_Xcaptions.shape:  (9, 30, 50)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "counter:  5\n",
      "minibatch_H.shape:  (9, 500, 30)\n",
      "minibatch_Ipast.shape:  (9, 30, 30)\n",
      "minibatch_Ifuture.shape:  (9, 30, 30)\n",
      "minibatch_Ycaptions.shape:  (9, 30, 51)\n",
      "minibatch_Xcaptions.shape:  (9, 30, 50)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "counter:  6\n",
      "minibatch_H.shape:  (9, 500, 30)\n",
      "minibatch_Ipast.shape:  (9, 30, 30)\n",
      "minibatch_Ifuture.shape:  (9, 30, 30)\n",
      "minibatch_Ycaptions.shape:  (9, 30, 51)\n",
      "minibatch_Xcaptions.shape:  (9, 30, 50)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "counter:  7\n",
      "minibatch_H.shape:  (9, 500, 30)\n",
      "minibatch_Ipast.shape:  (9, 30, 30)\n",
      "minibatch_Ifuture.shape:  (9, 30, 30)\n",
      "minibatch_Ycaptions.shape:  (9, 30, 51)\n",
      "minibatch_Xcaptions.shape:  (9, 30, 50)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "counter:  8\n",
      "minibatch_H.shape:  (9, 500, 30)\n",
      "minibatch_Ipast.shape:  (9, 30, 30)\n",
      "minibatch_Ifuture.shape:  (9, 30, 30)\n",
      "minibatch_Ycaptions.shape:  (9, 30, 51)\n",
      "minibatch_Xcaptions.shape:  (9, 30, 50)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "counter:  9\n",
      "minibatch_H.shape:  (9, 500, 30)\n",
      "minibatch_Ipast.shape:  (9, 30, 30)\n",
      "minibatch_Ifuture.shape:  (9, 30, 30)\n",
      "minibatch_Ycaptions.shape:  (9, 30, 51)\n",
      "minibatch_Xcaptions.shape:  (9, 30, 50)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "counter:  10\n",
      "minibatch_H.shape:  (9, 500, 30)\n",
      "minibatch_Ipast.shape:  (9, 30, 30)\n",
      "minibatch_Ifuture.shape:  (9, 30, 30)\n",
      "minibatch_Ycaptions.shape:  (9, 30, 51)\n",
      "minibatch_Xcaptions.shape:  (9, 30, 50)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "epoch:  2\n",
      "counter:  0\n",
      "minibatch_H.shape:  (9, 500, 30)\n",
      "minibatch_Ipast.shape:  (9, 30, 30)\n",
      "minibatch_Ifuture.shape:  (9, 30, 30)\n",
      "minibatch_Ycaptions.shape:  (9, 30, 51)\n",
      "minibatch_Xcaptions.shape:  (9, 30, 50)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counter:  1\n",
      "minibatch_H.shape:  (9, 500, 30)\n",
      "minibatch_Ipast.shape:  (9, 30, 30)\n",
      "minibatch_Ifuture.shape:  (9, 30, 30)\n",
      "minibatch_Ycaptions.shape:  (9, 30, 51)\n",
      "minibatch_Xcaptions.shape:  (9, 30, 50)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "counter:  2\n",
      "minibatch_H.shape:  (9, 500, 30)\n",
      "minibatch_Ipast.shape:  (9, 30, 30)\n",
      "minibatch_Ifuture.shape:  (9, 30, 30)\n",
      "minibatch_Ycaptions.shape:  (9, 30, 51)\n",
      "minibatch_Xcaptions.shape:  (9, 30, 50)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "counter:  3\n",
      "minibatch_H.shape:  (9, 500, 30)\n",
      "minibatch_Ipast.shape:  (9, 30, 30)\n",
      "minibatch_Ifuture.shape:  (9, 30, 30)\n",
      "minibatch_Ycaptions.shape:  (9, 30, 51)\n",
      "minibatch_Xcaptions.shape:  (9, 30, 50)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "counter:  4\n",
      "minibatch_H.shape:  (9, 500, 30)\n",
      "minibatch_Ipast.shape:  (9, 30, 30)\n",
      "minibatch_Ifuture.shape:  (9, 30, 30)\n",
      "minibatch_Ycaptions.shape:  (9, 30, 51)\n",
      "minibatch_Xcaptions.shape:  (9, 30, 50)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "counter:  5\n",
      "minibatch_H.shape:  (9, 500, 30)\n",
      "minibatch_Ipast.shape:  (9, 30, 30)\n",
      "minibatch_Ifuture.shape:  (9, 30, 30)\n",
      "minibatch_Ycaptions.shape:  (9, 30, 51)\n",
      "minibatch_Xcaptions.shape:  (9, 30, 50)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "counter:  6\n",
      "minibatch_H.shape:  (9, 500, 30)\n",
      "minibatch_Ipast.shape:  (9, 30, 30)\n",
      "minibatch_Ifuture.shape:  (9, 30, 30)\n",
      "minibatch_Ycaptions.shape:  (9, 30, 51)\n",
      "minibatch_Xcaptions.shape:  (9, 30, 50)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "counter:  7\n",
      "minibatch_H.shape:  (9, 500, 30)\n",
      "minibatch_Ipast.shape:  (9, 30, 30)\n",
      "minibatch_Ifuture.shape:  (9, 30, 30)\n",
      "minibatch_Ycaptions.shape:  (9, 30, 51)\n",
      "minibatch_Xcaptions.shape:  (9, 30, 50)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "counter:  8\n",
      "minibatch_H.shape:  (9, 500, 30)\n",
      "minibatch_Ipast.shape:  (9, 30, 30)\n",
      "minibatch_Ifuture.shape:  (9, 30, 30)\n",
      "minibatch_Ycaptions.shape:  (9, 30, 51)\n",
      "minibatch_Xcaptions.shape:  (9, 30, 50)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "counter:  9\n",
      "minibatch_H.shape:  (9, 500, 30)\n",
      "minibatch_Ipast.shape:  (9, 30, 30)\n",
      "minibatch_Ifuture.shape:  (9, 30, 30)\n",
      "minibatch_Ycaptions.shape:  (9, 30, 51)\n",
      "minibatch_Xcaptions.shape:  (9, 30, 50)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "counter:  10\n",
      "minibatch_H.shape:  (9, 500, 30)\n",
      "minibatch_Ipast.shape:  (9, 30, 30)\n",
      "minibatch_Ifuture.shape:  (9, 30, 30)\n",
      "minibatch_Ycaptions.shape:  (9, 30, 51)\n",
      "minibatch_Xcaptions.shape:  (9, 30, 50)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "Cost after epoch 2: 127064.194602\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7c84a60b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'parameters' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-eeb544497711>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Xcaptions.shape: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXcaptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIpast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIfuture\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYcaptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXcaptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword2id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-337d082b6b34>\u001b[0m in \u001b[0;36mmodel\u001b[0;34m(H_train, Ipast_train, Ifuture_train, Ycaptions_train, Xcaptions_train, word2id_len, learning_rate, num_epochs, minibatch_size, print_cost, num_layers, hidden_dim)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;31m# lets save the parameters in a variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Parameters have been trained!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'parameters' referenced before assignment"
     ]
    }
   ],
   "source": [
    "\n",
    "# Baseline Test Case\n",
    "H = padded_proposals.astype(np.float32)\n",
    "framestamps = padded_framestamps\n",
    "Ipast = temporal_indicator(framestamps, mode=\"past\")\n",
    "Ipast = Ipast.astype(np.float32)\n",
    "Ifuture = temporal_indicator(framestamps, mode=\"future\")\n",
    "Ifuture = Ifuture.astype(np.float32)\n",
    "emb_matrix, word2id, id2word = get_wordvector(embedding_size,vocab_size,vocabulary) #changed by Songze\n",
    "sentence_ids = all_padded_sentences_id\n",
    "Ycaptions = copy.deepcopy(all_padded_sentences_2) # holds i\n",
    "Xcaptions = copy.deepcopy(all_padded_sentences)\n",
    "\n",
    "Xcaptions = Xcaptions.astype(np.int32)\n",
    "Ycaptions = Ycaptions.astype(np.int32)\n",
    "\n",
    "Xcaptions = np.transpose(Xcaptions,axes=(0,2,1))\n",
    "Ycaptions = np.transpose(Ycaptions,axes=(0,2,1))\n",
    "\n",
    "print(Ycaptions.dtype)\n",
    "\n",
    "print(\"H.shape: \", H.shape)\n",
    "print(\"framestamps.shape: \", framestamps.shape)\n",
    "print(\"Ipast.shape: \", Ipast.shape)\n",
    "print(\"Ifuture.shape: \", Ifuture.shape)\n",
    "print(\"Ycaptions.shape: \", Ycaptions.shape)\n",
    "print(\"Xcaptions.shape: \", Xcaptions.shape)\n",
    "\n",
    "model(H, Ipast, Ifuture, Ycaptions, Xcaptions,len(word2id))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ignore Code Below for Now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_loss(self):\n",
    "       \"\"\"\n",
    "       Add loss computation to the graph.\n",
    "\n",
    "       Uses:\n",
    "         self.logits_start: shape (batch_size, context_len)\n",
    "           IMPORTANT: Assumes that self.logits_start is masked (i.e. has -large in masked locations).\n",
    "           That's because the tf.nn.sparse_softmax_cross_entropy_with_logits\n",
    "           function applies softmax and then computes cross-entropy loss.\n",
    "           So you need to apply masking to the logits (by subtracting large\n",
    "           number in the padding location) BEFORE you pass to the\n",
    "           sparse_softmax_cross_entropy_with_logits function.\n",
    "\n",
    "         self.ans_span: shape (batch_size, 2)\n",
    "           Contains the gold start and end locations\n",
    "\n",
    "       Defines:\n",
    "         self.loss_start, self.loss_end, self.loss: all scalar tensors\n",
    "       \"\"\"\n",
    "       with vs.variable_scope(\"loss\"):\n",
    "\n",
    "           # Calculate loss for prediction of start position\n",
    "           loss_start = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=self.logits_start, labels=self.ans_span[:, 0]) # loss_start has shape (batch_size)\n",
    "           self.loss_start = tf.reduce_mean(loss_start) # scalar. avg across batch\n",
    "           tf.summary.scalar('loss_start', self.loss_start) # log to tensorboard\n",
    "\n",
    "           # Calculate loss for prediction of end position\n",
    "           loss_end = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=self.logits_end, labels=self.ans_span[:, 1])\n",
    "           self.loss_end = tf.reduce_mean(loss_end)\n",
    "           tf.summary.scalar('loss_end', self.loss_end)\n",
    "\n",
    "           # Add the two losses\n",
    "           self.loss = self.loss_start + self.loss_end\n",
    "           tf.summary.scalar('loss', self.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(Hout,Sout,embeddings,word2id,rnn_outputs,x,y):\n",
    "    state_size = 512\n",
    "    batch_size = Hout.shape[0]\n",
    "    num_steps = Sout[1]\n",
    "    num_classes = embeddings[1]\n",
    "    num_layers = 2\n",
    "    initializer = Hout\n",
    "    \n",
    "    with tf.variable_scope('softmax'):\n",
    "        W = tf.get_variable('W', [state_size, num_classes])\n",
    "        b = tf.get_variable('b', [num_classes], initializer=tf.constant_initializer(0.0))\n",
    "    #reshape rnn_outputs and y so we can get the logits in a single matmul\n",
    "    rnn_outputs = tf.reshape(rnn_outputs, [-1, state_size])\n",
    "    y_reshaped = tf.reshape(y, [-1])\n",
    "    logits = tf.matmul(rnn_outputs, W) + b\n",
    "    losses = tf.reshape(tf.nn.sparse_softmax_cross_entropy_with_logits(logits, y_reshaped),[batch_size, num_steps])\n",
    "    loss_by_timestep = tf.reduce_mean(losses, reduction_indices=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_embedding_layer(sentence_ids,emb_matrix):\n",
    "    \"\"\"\n",
    "    Adds word embedding layer to the graph.\n",
    "\n",
    "    Inputs:\n",
    "      emb_matrix: shape (400002, embedding_size).\n",
    "      The Glove vectors, plus vectors for PAD and UNK.\n",
    "    \"\"\"\n",
    "    #with vs.variable_scope(\"embeddings\"):\n",
    "\n",
    "    # Note: the embedding matrix is a tf.constant which means it's not a trainable parameter\n",
    "    embedding_matrix = tf.constant(emb_matrix, dtype=tf.float32, name=\"emb_matrix\") # shape (400002, embedding_size)\n",
    "\n",
    "    # Get the word embeddings for the caption\n",
    "    # using the placeholders caption\n",
    "    #cap_embs = embedding_ops.embedding_lookup(embedding_matrix, sentence_ids) # shape (batch_size, context_len, embedding_size)\n",
    "    cap_embs = tf.nn.embedding_lookup(embedding_matrix, sentence_ids)\n",
    "       \n",
    "    return cap_embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = model(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Data (incomplete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_ids = [line.strip() for line in open(\"id_data/train_ids.csv\", 'r')]\n",
    "filename = \"c3d_data/sub_activitynet_v1-3.c3d.hdf5\"\n",
    "video_feature_representation = h5py.File(filename, 'r')\n",
    "train_ids = [\"v_--0edUL8zmA\",\"v_hHiPEAiYKv0\",\"v_u2uoYvo8J5s\",\"v_c_NlYvL96y0\",\"v_sJFgo9H6zNo\"]\n",
    "video_data = dict()\n",
    "for videoid in train_ids:\n",
    "    print(videoid)\n",
    "    proposals_df = pd.read_csv('prop_data/' + videoid + '.csv',sep=' ')\n",
    "    c3d_features = video_feature_representation[videoid]['c3d_features'].value\n",
    "    max_frames = c3d_features.shape[0]\n",
    "    print(max_frames)\n",
    "    \n",
    "    for i in range(proposals_df.shape[0]):\n",
    "        f_init = proposals_df[\"f-init\"][i]\n",
    "        f_end =  proposals_df[\"f-end\"][i]\n",
    "        if (f_init < max_frames) and (f_end > 0):\n",
    "            if f_init < 0:\n",
    "                f_init = 0\n",
    "            if f_end > max_frames:\n",
    "                f_end = max_frames\n",
    "        \n",
    "            #print((f_init,f_end))\n",
    "            #print(c3d_features[f_init:f_end,:].shape)\n",
    "            h = temporal_pooling(c3d_features[f_init:f_end,:], mode=\"max\")\n",
    "            if i == 0:\n",
    "                H = h\n",
    "            else:\n",
    "                H = np.column_stack((H,h))\n",
    "        else:\n",
    "            proposals_df.drop(proposals_df.index[i])\n",
    "    video_data[videoid] = H\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
