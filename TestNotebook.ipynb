{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shared/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "# As usual, a bit of setup\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import LOUPE.WILLOW.loupe as lp\n",
    "import tensorflow as tf\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import csv\n",
    "import copy\n",
    "import math\n",
    "from utils.data_utils import temporal_indicator\n",
    "from utils.data_utils import temporal_pooling\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load small training data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of examples:  99\n",
      "train_data.shape:  (590, 508)\n",
      "padded_proposals.shape:  (99, 500, 30)\n",
      "padded_framestamps.shape:  (99, 2, 30)\n"
     ]
    }
   ],
   "source": [
    "# format\n",
    "train_data = pd.read_csv(\"train_extreme_small.csv\")\n",
    "train_data.rename( columns={'Unnamed: 0':'index'}, inplace=True )\n",
    "train_data[\"duration\"] = train_data[\"duration\"].astype('float32')\n",
    "train_data[\"t_init\"], train_data[\"t_end\"] = train_data[\"timestamps\"].str.split(\", \", 1).str\n",
    "train_data[\"t_init\"] = train_data[\"t_init\"].str.strip(\"[\")\n",
    "train_data[\"t_end\"] = train_data[\"t_end\"].str.strip(\"]\")\n",
    "train_data[\"t_init\"] = train_data[\"t_init\"].astype('float32')\n",
    "train_data[\"t_end\"] = train_data[\"t_end\"].astype('float32')\n",
    "train_data = train_data.drop('timestamps', 1)\n",
    "\n",
    "# pool\n",
    "filename = \"/home/songzeli/Data/sub_activitynet_v1-3.c3d.hdf5\"\n",
    "video_feature_representation = h5py.File(filename, 'r')\n",
    "train_ids = train_data['id'].unique()\n",
    "f_inits = []\n",
    "f_ends = []\n",
    "max_pooled_representations = []\n",
    "max_proposals = 0\n",
    "padded_proposals = np.zeros((99,500,30))\n",
    "padded_framestamps = -1*np.ones((99,2,30))\n",
    "for v,video_id in enumerate(train_ids):\n",
    "    #print(\"video id: \", video_id)\n",
    "    temp = train_data[train_data['id']==video_id].reset_index()\n",
    "    C3D_features = video_feature_representation[\"v_QOlSCBRmfWY\"]['c3d_features'].value\n",
    "    \n",
    "    if max_proposals < temp.shape[0]:\n",
    "        max_proposals = temp.shape[0]\n",
    "    \n",
    "    for i in range(temp.shape[0]):\n",
    "        \n",
    "        # get time info\n",
    "        duration = temp[\"duration\"][i]\n",
    "        t_init = temp[\"t_init\"][i]\n",
    "        t_end = temp[\"t_end\"][i]\n",
    "        num_frames = C3D_features.shape[0]\n",
    "        \n",
    "        # compute start and end frame\n",
    "        f_init = int(round((t_init/duration)*num_frames))\n",
    "        f_end = int(round((t_end/duration)*num_frames))\n",
    "        #print(\"f_init: \", f_init, \"t_init: \", t_init)\n",
    "        #print(\"f_end: \", f_end, \"t_end: \", t_end)\n",
    "        \n",
    "        # get max pool\n",
    "        if f_init <= f_end:\n",
    "            max_pooled_rep = temporal_pooling(C3D_features[f_init:f_end],\"max\")\n",
    "        else:\n",
    "            max_pooled_rep = temporal_pooling(C3D_features[f_end:f_init],\"max\")\n",
    "        \n",
    "        # append info\n",
    "        f_inits.append(f_init)\n",
    "        f_ends.append(f_end)\n",
    "        max_pooled_representations.append(max_pooled_rep)\n",
    "        padded_proposals[v,:,i] = max_pooled_rep\n",
    "        padded_framestamps[v,0,i] = f_init\n",
    "        padded_framestamps[v,1,i] = f_end\n",
    "\n",
    "\n",
    "f_inits = np.array(f_inits)\n",
    "f_inits = pd.DataFrame({'f_init': f_inits})\n",
    "f_ends = np.array(f_ends) \n",
    "f_ends = pd.DataFrame({'f_end': f_ends})\n",
    "\n",
    "max_pooled_representations = np.array(max_pooled_representations)\n",
    "C3D_feature_column_names = [\"h\" + str(i) for i in range(max_pooled_representations.shape[1])] \n",
    "max_pooled_representations = pd.DataFrame(max_pooled_representations, columns=C3D_feature_column_names)\n",
    "\n",
    "train_data = pd.concat([train_data, f_inits, f_ends, max_pooled_representations], axis=1)\n",
    "\n",
    "\n",
    "train_data.to_pickle(\"train_data\")\n",
    "\n",
    "print(\"number of examples: \", train_ids.shape[0])\n",
    "print(\"train_data.shape: \", train_data.shape)\n",
    "print(\"padded_proposals.shape: \", padded_proposals.shape)\n",
    "print(\"padded_framestamps.shape: \", padded_framestamps.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get word2id in sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words in all captions:  504895\n",
      "Vocabulary Size (Unique):  13001\n"
     ]
    }
   ],
   "source": [
    "#Changed by Songze\n",
    "train_voc = pd.read_csv(\"train_all.csv\")\n",
    "train_voc.rename( columns={'Unnamed: 0':'index'}, inplace=True )\n",
    "train_voc[\"duration\"] = train_voc[\"duration\"].astype('float32')\n",
    "train_voc[\"t_init\"], train_voc[\"t_end\"] = train_voc[\"timestamps\"].str.split(\", \", 1).str\n",
    "train_voc[\"t_init\"] = train_voc[\"t_init\"].str.strip(\"[\")\n",
    "train_voc[\"t_end\"] = train_voc[\"t_end\"].str.strip(\"]\")\n",
    "train_voc[\"t_init\"] = train_voc[\"t_init\"].astype('float32')\n",
    "train_voc[\"t_end\"] = train_voc[\"t_end\"].astype('float32')\n",
    "train_voc = train_voc.drop('timestamps', 1)\n",
    "from utils.data_utils import export_vocabulary\n",
    "export_vocabulary(train_voc)\n",
    "#Changed by Songze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10190"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Changed by Songze\n",
    "df = pd.read_csv('vocabulary.csv')\n",
    "voc = df[\"Unnamed: 0\"].tolist()\n",
    "vocabulary = []\n",
    "for word in voc:\n",
    "    if word.isalpha():\n",
    "        vocabulary.append(word)\n",
    "len(vocabulary)\n",
    "#Changed by Songze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changed by Songze\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "_PAD = b\"<pad>\"\n",
    "_UNK = b\"<unk>\"\n",
    "_STA = b\"<sta>\"\n",
    "_END = b\"<end>\"\n",
    "_START_VOCAB = [_PAD,_UNK,_STA,_END]\n",
    "PAD_ID = 0\n",
    "UNK_ID = 1\n",
    "STA_ID = 2\n",
    "END_ID = 3\n",
    "\n",
    "# word_path = './vocabulary.csv'\n",
    "emb_dim = 512\n",
    "vocab_size = len(vocabulary)\n",
    "\n",
    "def get_wordvector(emb_dim,vocab_size,vocabulary):\n",
    "    \"\"\"Reads from original word lib file and returns embedding matrix and\n",
    "    mappings from words to word ids.\n",
    "\n",
    "    Returns:\n",
    "      emb_matrix: Numpy array shape (len(vocabulary), word_dim) containing word embeddings\n",
    "        (plus PAD and UNK embeddings in first 4 rows).\n",
    "        The rows of emb_matrix correspond to the word ids given in word2id and id2word\n",
    "      word2id: dictionary mapping word (string) to word id (int)\n",
    "      id2word: dictionary mapping word id (int) to word (string)\n",
    "    \"\"\"\n",
    "    \n",
    "    vocabulary = _START_VOCAB + vocabulary\n",
    "\n",
    "    emb_matrix = np.zeros((vocab_size + len(_START_VOCAB), emb_dim))\n",
    "    word2id = {}\n",
    "    id2word = {}\n",
    "\n",
    "    random_init = True\n",
    "    # randomly initialize all the tokens\n",
    "    emb_matrix[:, :] = np.random.randn(vocab_size + len(_START_VOCAB), emb_dim)\n",
    "\n",
    "    # put start tokens in the dictionaries\n",
    "    idx = 0\n",
    "    for word in vocabulary:\n",
    "        word2id[word] = idx\n",
    "        id2word[idx] = word\n",
    "        idx += 1\n",
    "\n",
    "\n",
    "    final_vocab_size = vocab_size + len(_START_VOCAB)\n",
    "    assert len(word2id) == final_vocab_size\n",
    "    assert len(id2word) == final_vocab_size\n",
    "    assert idx == final_vocab_size\n",
    "\n",
    "    return emb_matrix, word2id, id2word\n",
    "\n",
    "emb_matrix,word2id,id2word = get_wordvector(emb_dim,vocab_size,vocabulary)\n",
    "\n",
    "#Changed by Songze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_padded_sentences_2.shape:  (99, 51, 30)\n"
     ]
    }
   ],
   "source": [
    "#Changed by Songze\n",
    "def split_by_whitespace(sentence):\n",
    "    words = []\n",
    "    for space_separated_fragment in sentence.strip().split():\n",
    "        words.extend(re.split(\" \", space_separated_fragment))\n",
    "    return [w for w in words if w]\n",
    "\n",
    "\n",
    "def intstr_to_intlist(string):\n",
    "    \"\"\"Given a string e.g. '311 9 1334 635 6192 56 639', returns as a list of integers\"\"\"\n",
    "    return [int(s) for s in string.split()]\n",
    "\n",
    "\n",
    "def sentence_to_token_ids(sentence, word2id):\n",
    "    \"\"\"Turns an already-tokenized sentence string into word indices\n",
    "    e.g. \"i do n't know\" -> [9, 32, 16, 96]\n",
    "    Note any token that isn't in the word2id mapping gets mapped to the id for UNK\n",
    "    \"\"\"\n",
    "    tokens = split_by_whitespace(sentence) # list of strings\n",
    "    ids = [word2id.get(w.lower(), UNK_ID) for w in tokens]\n",
    "    return tokens, ids\n",
    "\n",
    "\n",
    "def padded(token_batch, batch_pad=0):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "      token_batch: List (length batch size) of lists of ints.\n",
    "      batch_pad: Int. Length to pad to. If 0, pad to maximum length sequence in token_batch.\n",
    "    Returns:\n",
    "      List (length batch_size) of padded lists of ints.\n",
    "        All are same length - batch_pad if batch_pad!=0, otherwise the maximum length in token_batch\n",
    "    \"\"\"\n",
    "    maxlen = max(lambda x: len(x), token_batch) if batch_pad == 0 else batch_pad\n",
    "    res = [STA_ID]+token_batch+[END_ID]+[PAD_ID] * (maxlen - len(token_batch)-2)\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "import re\n",
    "#padding for sentences\n",
    "pad_len = 50\n",
    "\n",
    "all_padded_sentences = np.zeros((99,pad_len,30))\n",
    "for v,video_id in enumerate(train_ids):\n",
    "    temp = train_data[train_data['id']==video_id].reset_index()\n",
    "    for i in range(temp.shape[0]):\n",
    "        words,ids = sentence_to_token_ids(temp['sentences'][i][:-1],word2id)\n",
    "        ids_pad = padded(ids,pad_len)\n",
    "        all_padded_sentences[v,:,i] = ids_pad\n",
    "\n",
    "                   \n",
    "all_padded_sentences_2 = np.zeros((99,pad_len+1,30))\n",
    "for v,video_id in enumerate(train_ids):\n",
    "    temp = train_data[train_data['id']==video_id].reset_index()\n",
    "    for i in range(temp.shape[0]):\n",
    "        words,ids = sentence_to_token_ids(temp['sentences'][i][:-1],word2id)\n",
    "        ids_pad = padded(ids,pad_len+1)\n",
    "        all_padded_sentences_2[v,:,i] = ids_pad\n",
    "\n",
    "all_padded_sentences_id = np.array(all_padded_sentences).astype(int)\n",
    "        \n",
    "print(\"all_padded_sentences_2.shape: \", all_padded_sentences_2.shape)\n",
    "#Changed by Songze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_module(H, Ipast, Ifuture, num_proposals, num_c3d_features, num_steps, batch_size):\n",
    "    \"\"\"\n",
    "    Implements the attention module: see https://cs.stanford.edu/people/ranjaykrishna/densevid/\n",
    "    \n",
    "    Arguments:\n",
    "    H -- input dataset placeholder, of shape = [None, N, K] and dtype \"float\"\n",
    "    Ipast -- placeholder for the indicators of past, shape = [None, K, K] and dtype \"float\"\n",
    "    Ifuture == placeholder for the indicators of future, shape = [None, K, K] and dtype \"float\"\n",
    "    parameters -- python dictionary containing your parameters \"Wa\", \"ba\", sapes [N,N] and [N,1] respectively\n",
    "\n",
    "    Returns:\n",
    "    Hout -- concatenated output (hpast, h, hfuture), shape = [batch_size, 3*num_c3d_features, num_proposals]\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"H dtype: \", H.dtype)\n",
    "    print(\"Ipast dtype: \", Ipast.dtype)\n",
    "    print(\"Ifuture dtype: \", Ifuture.dtype)\n",
    "    #print(\"x dtype: \", x.dtype)\n",
    "    #print(\"y dtype: \", y.dtype)\n",
    "    \n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    Wa = tf.get_variable(\"Wa\", [num_c3d_features,num_c3d_features], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    ba = tf.get_variable(\"ba\", [num_c3d_features,1], initializer = tf.zeros_initializer())\n",
    "\n",
    "    # forward pass\n",
    "    W = tf.transpose(tf.tensordot(Wa,tf.transpose(H,perm=[1,2,0]),axes=[[1], [0]]),perm=[2,0,1]) + ba # shape: [None,num_proposals,num_proposals]\n",
    "    A = tf.matmul(tf.transpose(W,perm=[0,2,1]),H) # shape: [None,num_proposals,num_proposals]\n",
    "    A_flat = tf.reshape(A, [-1, num_proposals*num_proposals]) # shape: [None,num_proposals*num_proposals]\n",
    "\n",
    "    # future features\n",
    "    Ifuture_flat = tf.reshape(Ifuture, [-1, num_proposals*num_proposals]) # shape: [None,K*K]\n",
    "    Afuture = tf.reshape(tf.multiply(Ifuture_flat,A_flat),[-1,num_proposals,num_proposals]) # shape: [None,K,K]\n",
    "    Zfuture = tf.reduce_sum(Ifuture,axis=2) # shape: [None,num_proposals]\n",
    "    Hfuture = tf.transpose(tf.transpose(tf.matmul(H,tf.transpose(Afuture,perm=[0,2,1])),perm=[1,0,2])/Zfuture,perm=[1,0,2]) # shape: [None,num_c3d_features,num_proposals]\n",
    "\n",
    "    # past features\n",
    "    Ipast_flat = tf.reshape(Ipast, [-1, num_proposals*num_proposals]) # shape: [None,num_proposals*num_proposals]\n",
    "    Apast = tf.reshape(tf.multiply(Ipast_flat,A_flat),[-1,num_proposals,num_proposals]) # shape: [None,num_proposals,num_proposals]\n",
    "    Zpast = tf.reduce_sum(Ipast,axis=2) # shape: [None,num_proposals]\n",
    "    Hpast = tf.transpose(tf.transpose(tf.matmul(H,tf.transpose(Apast,perm=[0,2,1])),perm=[1,0,2])/Zfuture,perm=[1,0,2]) # shape: [None,num_c3d_features,num_proposals]\n",
    "\n",
    "    # stacked features\n",
    "    Hout = tf.concat([Hpast, H, Hfuture], 1)\n",
    "\n",
    "    print(\"Hfuture shape: \", Hfuture.get_shape().as_list())\n",
    "    print(\"W shape: \", W.get_shape().as_list())\n",
    "    print(\"A shape: \", A.get_shape().as_list())\n",
    "    print(\"A_flat shape: \", A_flat.get_shape().as_list())\n",
    "    print(\"Ifuture_flat shape: \", Ifuture_flat.get_shape().as_list())\n",
    "    print(\"Zfuture: \", Zfuture.get_shape().as_list())\n",
    "    print(\"Hfuture: \", Hfuture.get_shape().as_list())\n",
    "    print(\"Hpast: \", Hfuture.get_shape().as_list())\n",
    "    print(\"Hout: \", Hout.get_shape().as_list())\n",
    "    \n",
    "    return Hout\n",
    "\n",
    "def language_module(Hout, x, num_classes, hidden_dim, num_steps, num_proposals, num_layers, batch_size):\n",
    "    '''\n",
    "    Inputs: \n",
    "      number of classes\n",
    "      hidden_dim = number units in lstm and word embedding\n",
    "      num_steps, length of captions\n",
    "      num_steps\n",
    "      num_layers \n",
    "      batch_size\n",
    "    '''\n",
    "    \n",
    "    Hout = tf.transpose(Hout, perm=[0,2,1])\n",
    "    Hout = tf.reshape(Hout, [-1, 1500])\n",
    "    \n",
    "    # create placeholder\n",
    "    #x_captions = tf.placeholder(tf.int32, [batch_size, num_proposals, num_steps], name=\"x_captions\")\n",
    "    \n",
    "    \n",
    "    feature_inputs = tf.expand_dims(tf.layers.dense(inputs=Hout,units=hidden_dim,activation=tf.nn.relu),1)\n",
    "    print(\"feature_inputs.shape: \",feature_inputs.get_shape().as_list())\n",
    "\n",
    "    embeddings = tf.get_variable('embedding_matrix', [num_classes, hidden_dim])\n",
    "    embedding_inputs = tf.nn.embedding_lookup(embeddings, tf.reshape(x,[-1,num_steps]))\n",
    "    print(\"embedding_inputs.shape: \",embedding_inputs.get_shape().as_list())\n",
    "                                              \n",
    "    lstm_inputs = tf.concat(values=[feature_inputs, embedding_inputs],axis=1)\n",
    "    print(\"all_inputs.shape: \", lstm_inputs.get_shape().as_list())                                      \n",
    "    \n",
    "    lstm_cell = tf.nn.rnn_cell.LSTMCell(num_units=hidden_dim,state_is_tuple=True)\n",
    "    lstm_cells = tf.nn.rnn_cell.MultiRNNCell([lstm_cell] * num_layers, state_is_tuple=True)\n",
    "    initial_state = lstm_cells.zero_state(batch_size*num_proposals, tf.float32)\n",
    "    lstm_outputs, final_state = tf.nn.dynamic_rnn(cell=lstm_cells,inputs=lstm_inputs,initial_state=initial_state)\n",
    "    print(\"lstm_outputs.shape: \", lstm_outputs.get_shape().as_list())                                         \n",
    "                                              \n",
    "    logits = tf.layers.dense(inputs=tf.reshape(lstm_outputs,[-1,hidden_dim]),units=num_classes)\n",
    "                                         \n",
    "    predictions = tf.argmax(logits,1)\n",
    "    predictions = tf.reshape(predictions, [batch_size,num_proposals,num_steps+1])\n",
    "    print(\"predictions.shape: \", predictions.get_shape().as_list())\n",
    "    \n",
    "    logits = tf.reshape(logits, [batch_size,num_proposals,num_steps+1,num_classes])\n",
    "    print(\"logits.shape: \", logits.get_shape().as_list())\n",
    "                                                                            \n",
    "    return predictions, logits\n",
    "\n",
    "def caption_cost(y, logits, num_classes, num_proposals,num_steps,batch_size):\n",
    "    print(\"y_captions.shape: \", y.get_shape().as_list())\n",
    "    print()\n",
    "    loss = tf.reduce_sum(\n",
    "        tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "            logits=tf.reshape(logits,[-1,num_classes]), \n",
    "            labels=tf.reshape(y,[-1])\n",
    "        )\n",
    "    )\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Forward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H dtype:  <dtype: 'float32'>\n",
      "Ipast dtype:  <dtype: 'float32'>\n",
      "Ifuture dtype:  <dtype: 'float32'>\n",
      "Hfuture shape:  [9, 500, 30]\n",
      "W shape:  [9, 500, 30]\n",
      "A shape:  [9, 30, 30]\n",
      "A_flat shape:  [9, 900]\n",
      "Ifuture_flat shape:  [9, 900]\n",
      "Zfuture:  [9, 30]\n",
      "Hfuture:  [9, 500, 30]\n",
      "Hpast:  [9, 500, 30]\n",
      "Hout:  [9, 1500, 30]\n",
      "feature_inputs.shape:  [270, 1, 512]\n",
      "embedding_inputs.shape:  [270, 50, 512]\n",
      "all_inputs.shape:  [270, 51, 512]\n",
      "lstm_outputs.shape:  [270, 51, 512]\n",
      "predictions.shape:  [9, 30, 51]\n",
      "logits.shape:  [9, 30, 51, 10194]\n",
      "y_captions.shape:  [9, 30, 51]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "H_train = padded_proposals.astype(np.float32)\n",
    "framestamps = padded_framestamps\n",
    "Ipast = temporal_indicator(framestamps, mode=\"past\")\n",
    "Ipast_train = Ipast.astype(np.float32)\n",
    "Ifuture = temporal_indicator(framestamps, mode=\"future\")\n",
    "Ifuture_train = Ifuture.astype(np.float32)\n",
    "emb_matrix, word2id, id2word = get_wordvector(emb_dim,vocab_size,vocabulary) #changed by Songze\n",
    "sentence_ids = all_padded_sentences_id\n",
    "Ycaptions = copy.deepcopy(all_padded_sentences_2) # holds i\n",
    "Xcaptions = copy.deepcopy(all_padded_sentences)\n",
    "Xcaptions = Xcaptions.astype(np.int32)\n",
    "Ycaptions = Ycaptions.astype(np.int32)\n",
    "Xcaptions_train = np.transpose(Xcaptions,axes=(0,2,1))\n",
    "Ycaptions_train = np.transpose(Ycaptions,axes=(0,2,1))\n",
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "num_c3d_features = 500\n",
    "num_classes = len(word2id)\n",
    "hidden_dim = 512\n",
    "num_steps = 50\n",
    "num_proposals = 30\n",
    "num_layers = 2\n",
    "batch_size = 9\n",
    "\n",
    "tf.reset_default_graph()\n",
    "# create placeholders\n",
    "H = tf.placeholder(tf.float32,shape=[batch_size, num_c3d_features, num_proposals], name=\"H\")\n",
    "Ipast = tf.placeholder(tf.float32, shape=[batch_size, num_proposals, num_proposals], name=\"Ipast\")\n",
    "Ifuture = tf.placeholder(tf.float32, shape=[batch_size, num_proposals, num_proposals], name=\"Ifuture\")\n",
    "x = tf.placeholder(tf.int32, [batch_size, num_proposals, num_steps], name=\"x\")\n",
    "y = tf.placeholder(tf.int32, [batch_size, num_proposals, num_steps+1], name=\"y\")\n",
    "\n",
    "# forward pass\n",
    "Hout = attention_module(H, Ipast, Ifuture, num_proposals, num_c3d_features, num_steps, batch_size)\n",
    "predictions, logits = language_module(Hout, x, num_classes, hidden_dim, num_steps, num_proposals, num_layers, batch_size)\n",
    "cap_loss = caption_cost(y, logits, num_classes, num_proposals,num_steps,batch_size)\n",
    "\n",
    "\n",
    "# check forward pass\n",
    "#with tf.Session() as sess:\n",
    "#    # Run the initialization\n",
    "#    sess.run(init)\n",
    "#    minibatch_cost = sess.run([cap_loss], feed_dict={H: H_train[0:batch_size], Ipast: Ipast_train[0:batch_size], Ifuture: Ifuture_train[0:batch_size], x: Xcaptions_train[0:batch_size], y: Ycaptions_train[0:batch_size]})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(H_train, Ipast_train, Ifuture_train, Ycaptions_train, Xcaptions_train, learning_rate = 0.001, num_epochs = 3, minibatch_size = 9, print_cost = True):\n",
    "    \"\"\"\n",
    "    Implements a tensorflow neural network: C3D->DAPS->ATTENTION->CAPTIONING\n",
    "    \n",
    "    Arguments:\n",
    "    H_train -- training set, of shape = [n_train,num_c3d_features,num_proposals]\n",
    "    Y_train -- caption labels, of shape = [n_train,num_proposals,num_steps+1]\n",
    "    H_test -- training set, of shape = [n_test,num_c3d_features,num_proposals]\n",
    "    Y_test -- caption labels, of shape = [n_test,num_proposals,num_steps+1]\n",
    "    learning_rate -- learning rate of the optimization\n",
    "    num_epochs -- number of epochs of the optimization loop\n",
    "    minibatch_size -- size of a minibatch\n",
    "    print_cost -- True to print the cost every 100 epochs\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "    batch_size = minibatch_size\n",
    "    \n",
    "    # to be able to rerun the model without overwriting tf variables\n",
    "    tf.reset_default_graph()    \n",
    "    \n",
    "    # to keep consistent results\n",
    "    tf.set_random_seed(1)                             \n",
    "    seed = 3                                         \n",
    "    \n",
    "    # size values\n",
    "    (n_train,num_c3d_features,num_proposals) = H_train.shape                        \n",
    "    (_,_,num_steps) = Xcaptions_train.shape\n",
    "    num_classes = 400002\n",
    "    num_layers = 2\n",
    "    hidden_dim = 512\n",
    "    \n",
    "    print(\"n_train \", n_train)\n",
    "    print(\"num_c3d_features \", num_c3d_features)\n",
    "    print(\"num_proposals: \", num_proposals)\n",
    "    print(\"num_steps: \", num_steps)\n",
    "    \n",
    "    # to keep track of costs\n",
    "    costs = []  \n",
    "    \n",
    "    # create placeholders\n",
    "    H = tf.placeholder(tf.float32,shape=[batch_size, num_c3d_features, num_proposals], name=\"H\")\n",
    "    Ipast = tf.placeholder(tf.float32, shape=[batch_size, num_proposals, num_proposals], name=\"Ipast\")\n",
    "    Ifuture = tf.placeholder(tf.float32, shape=[batch_size, num_proposals, num_proposals], name=\"Ifuture\")\n",
    "    x = tf.placeholder(tf.int32, [batch_size, num_proposals, num_steps], name=\"x\")\n",
    "    y = tf.placeholder(tf.int32, [batch_size, num_proposals, num_steps+1], name=\"y\")\n",
    "    \n",
    "    # attention module\n",
    "    #attention_module(K,N, batch_size)\n",
    "    Hout = attention_module(\n",
    "        H,\n",
    "        Ipast,\n",
    "        Ifuture,\n",
    "        num_proposals, \n",
    "        num_c3d_features,\n",
    "        num_steps,\n",
    "        batch_size\n",
    "    )\n",
    "    \n",
    "    # language module\n",
    "    #language_module(Hout, num_classes, hidden_dim, num_steps, num_proposals, num_layers, batch_size)\n",
    "    predictions, logits = language_module(\n",
    "        Hout, \n",
    "        x,\n",
    "        num_classes, \n",
    "        hidden_dim, \n",
    "        num_steps, \n",
    "        num_proposals, \n",
    "        num_layers, \n",
    "        batch_size\n",
    "    )\n",
    "    \n",
    "    # cost\n",
    "    # caption_cost(logits, num_classes, num_proposals,num_steps,batch_size)\n",
    "    cap_loss = caption_cost(\n",
    "        y,\n",
    "        logits, \n",
    "        num_classes, \n",
    "        num_proposals, \n",
    "        num_steps, \n",
    "        batch_size\n",
    "    )\n",
    "    \n",
    "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer.\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cap_loss)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Initialize all the variables\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "        \n",
    "        # Do the training loop\n",
    "        for epoch in range(num_epochs):\n",
    "            print(\"epoch: \", epoch)\n",
    "\n",
    "            epoch_cost = 0.                       # Defines a cost related to an epoch\n",
    "            num_minibatches = int(n_train / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "            seed = seed + 1\n",
    "            minibatches = random_mini_batches(H_train, Ipast_train, Ifuture_train, Ycaptions_train, Xcaptions_train, minibatch_size, seed = 0)\n",
    "\n",
    "            for counter,minibatch in enumerate(minibatches):\n",
    "                print(\"counter: \", counter)\n",
    "\n",
    "                # Select a minibatch\n",
    "                (minibatch_H, minibatch_Ipast, minibatch_Ifuture, minibatch_Ycaptions, minibatch_Xcaptions) = minibatch\n",
    "                print(\"minibatch_H.shape: \", minibatch_H.shape)\n",
    "                print(\"minibatch_Ipast.shape: \", minibatch_Ipast.shape)\n",
    "                print(\"minibatch_Ifuture.shape: \", minibatch_Ifuture.shape)\n",
    "                print(\"minibatch_Ycaptions.shape: \", minibatch_Ycaptions.shape)\n",
    "                print(\"minibatch_Xcaptions.shape: \", minibatch_Xcaptions.shape)\n",
    "                \n",
    "                print(type(minibatch_H))\n",
    "                print(type(minibatch_Ipast))\n",
    "                print(type(minibatch_Ifuture))\n",
    "                print(type(minibatch_Ycaptions))\n",
    "                print(type(minibatch_Xcaptions))\n",
    "                \n",
    "                # The line that runs the graph on a minibatch.\n",
    "                _ , minibatch_cost = sess.run([optimizer, cap_loss], feed_dict={H: minibatch_H, Ipast: minibatch_Ipast, Ifuture: minibatch_Ifuture, x: minibatch_Xcaptions, y: minibatch_Ycaptions})\n",
    "\n",
    "                epoch_cost += minibatch_cost / num_minibatches\n",
    "\n",
    "            # Print the cost every epoch\n",
    "            if print_cost == True and epoch % 100 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "                \n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # lets save the parameters in a variable\n",
    "        parameters = sess.run(parameters)\n",
    "        print (\"Parameters have been trained!\")\n",
    "\n",
    "        # Calculate the correct predictions\n",
    "        correct_prediction = tf.equal(tf.argmax(Z3), tf.argmax(Y))\n",
    "\n",
    "        # Calculate accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "        print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n",
    "        print (\"Test Accuracy:\", accuracy.eval({X: X_test, Y: Y_test}))\n",
    "        \n",
    "        return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_mini_batches(H, Ipast, Ifuture, Ycaptions, Xcaptions, mini_batch_size = 9, seed = 0):\n",
    "    \"\"\"\n",
    "    Creates a list of random minibatches from (H, Ipast, Ifuture, Ycaptions, Xcaptions)\n",
    "    \n",
    "    Arguments:\n",
    "    H -- training set, of shape = [n_train,num_c3d_features,num_proposals]\n",
    "    Y -- caption labels, of shape = [n_train,num_proposals,num_steps+1]\n",
    "    mini_batch_size - size of the mini-batches, integer\n",
    "    seed -- this is only for the purpose of grading, so that you're \"random minibatches are the same as ours.\n",
    "    \n",
    "    Returns:\n",
    "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    X -- input data, of shape (input size, number of examples)\n",
    "    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)\n",
    "    mini_batch_size - size of the mini-batches, integer\n",
    "    seed -- this is only for the purpose of grading, so that you're \"random minibatches are the same as ours.\n",
    "    \n",
    "    Returns:\n",
    "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
    "     \"\"\"\n",
    "    \n",
    "    m = H.shape[0]                  # number of training examples\n",
    "    mini_batches = []\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Step 1: Shuffle (H, Ipast, Ifuture, Ycaptions, Xcaptions)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_H = H[permutation]\n",
    "    shuffled_Ipast = Ipast[permutation]\n",
    "    shuffled_Ifuture = Ifuture[permutation]\n",
    "    shuffled_Ycaptions = Ycaptions[permutation]\n",
    "    shuffled_Xcaptions = Xcaptions[permutation]\n",
    "    \n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        mini_batch_H = shuffled_H[k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
    "        mini_batch_Ipast = shuffled_Ipast[k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
    "        mini_batch_Ifuture = shuffled_Ifuture[k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
    "        mini_batch_Ycaptions = shuffled_Ycaptions[k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
    "        mini_batch_Xcaptions = shuffled_Xcaptions[k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
    "        mini_batch = (mini_batch_H, mini_batch_Ipast, mini_batch_Ifuture, mini_batch_Ycaptions, mini_batch_Xcaptions)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        mini_batch_H = shuffled_H[num_complete_minibatches * mini_batch_size : m]\n",
    "        mini_batch_Ipast = shuffled_Ipast[num_complete_minibatches * mini_batch_size : m]\n",
    "        mini_batch_Ifuture = shuffled_Ifuture[num_complete_minibatches * mini_batch_size : m]\n",
    "        mini_batch_Ycaptions = shuffled_Ycaptions[num_complete_minibatches * mini_batch_size : m]\n",
    "        mini_batch_Xcaptions = shuffled_Xcaptions[num_complete_minibatches * mini_batch_size : m]\n",
    "        mini_batch = (mini_batch_H, mini_batch_Ipast, mini_batch_Ifuture, mini_batch_Ycaptions, mini_batch_Xcaptions)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int32\n",
      "H.shape:  (99, 500, 30)\n",
      "framestamps.shape:  (99, 2, 30)\n",
      "Ipast.shape:  (99, 30, 30)\n",
      "Ifuture.shape:  (99, 30, 30)\n",
      "Ycaptions.shape:  (99, 30, 51)\n",
      "Xcaptions.shape:  (99, 30, 50)\n",
      "n_train  99\n",
      "num_c3d_features  500\n",
      "num_proposals:  30\n",
      "num_steps:  50\n",
      "H dtype:  <dtype: 'float32'>\n",
      "Ipast dtype:  <dtype: 'float32'>\n",
      "Ifuture dtype:  <dtype: 'float32'>\n",
      "Hfuture shape:  [9, 500, 30]\n",
      "W shape:  [9, 500, 30]\n",
      "A shape:  [9, 30, 30]\n",
      "A_flat shape:  [9, 900]\n",
      "Ifuture_flat shape:  [9, 900]\n",
      "Zfuture:  [9, 30]\n",
      "Hfuture:  [9, 500, 30]\n",
      "Hpast:  [9, 500, 30]\n",
      "Hout:  [9, 1500, 30]\n",
      "feature_inputs.shape:  [270, 1, 512]\n",
      "embedding_inputs.shape:  [270, 50, 512]\n",
      "all_inputs.shape:  [270, 51, 512]\n",
      "lstm_outputs.shape:  [270, 51, 512]\n",
      "predictions.shape:  [9, 30, 51]\n",
      "logits.shape:  [9, 30, 51, 400002]\n",
      "y_captions.shape:  [9, 30, 51]\n",
      "\n",
      "epoch:  0\n",
      "counter:  0\n",
      "minibatch_H.shape:  (9, 500, 30)\n",
      "minibatch_Ipast.shape:  (9, 30, 30)\n",
      "minibatch_Ifuture.shape:  (9, 30, 30)\n",
      "minibatch_Ycaptions.shape:  (9, 30, 51)\n",
      "minibatch_Xcaptions.shape:  (9, 30, 50)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# Baseline Test Case\n",
    "H = padded_proposals.astype(np.float32)\n",
    "framestamps = padded_framestamps\n",
    "Ipast = temporal_indicator(framestamps, mode=\"past\")\n",
    "Ipast = Ipast.astype(np.float32)\n",
    "Ifuture = temporal_indicator(framestamps, mode=\"future\")\n",
    "Ifuture = Ifuture.astype(np.float32)\n",
    "emb_matrix, word2id, id2word = get_wordvector(emb_dim,vocab_size,vocabulary) #changed by Songze\n",
    "sentence_ids = all_padded_sentences_id\n",
    "Ycaptions = copy.deepcopy(all_padded_sentences_2) # holds i\n",
    "Xcaptions = copy.deepcopy(all_padded_sentences)\n",
    "\n",
    "Xcaptions = Xcaptions.astype(np.int32)\n",
    "Ycaptions = Ycaptions.astype(np.int32)\n",
    "\n",
    "Xcaptions = np.transpose(Xcaptions,axes=(0,2,1))\n",
    "Ycaptions = np.transpose(Ycaptions,axes=(0,2,1))\n",
    "\n",
    "print(Ycaptions.dtype)\n",
    "\n",
    "print(\"H.shape: \", H.shape)\n",
    "print(\"framestamps.shape: \", framestamps.shape)\n",
    "print(\"Ipast.shape: \", Ipast.shape)\n",
    "print(\"Ifuture.shape: \", Ifuture.shape)\n",
    "print(\"Ycaptions.shape: \", Ycaptions.shape)\n",
    "print(\"Xcaptions.shape: \", Xcaptions.shape)\n",
    "\n",
    "model(H, Ipast, Ifuture, Ycaptions, Xcaptions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ignore Code Below for Now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_loss(self):\n",
    "       \"\"\"\n",
    "       Add loss computation to the graph.\n",
    "\n",
    "       Uses:\n",
    "         self.logits_start: shape (batch_size, context_len)\n",
    "           IMPORTANT: Assumes that self.logits_start is masked (i.e. has -large in masked locations).\n",
    "           That's because the tf.nn.sparse_softmax_cross_entropy_with_logits\n",
    "           function applies softmax and then computes cross-entropy loss.\n",
    "           So you need to apply masking to the logits (by subtracting large\n",
    "           number in the padding location) BEFORE you pass to the\n",
    "           sparse_softmax_cross_entropy_with_logits function.\n",
    "\n",
    "         self.ans_span: shape (batch_size, 2)\n",
    "           Contains the gold start and end locations\n",
    "\n",
    "       Defines:\n",
    "         self.loss_start, self.loss_end, self.loss: all scalar tensors\n",
    "       \"\"\"\n",
    "       with vs.variable_scope(\"loss\"):\n",
    "\n",
    "           # Calculate loss for prediction of start position\n",
    "           loss_start = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=self.logits_start, labels=self.ans_span[:, 0]) # loss_start has shape (batch_size)\n",
    "           self.loss_start = tf.reduce_mean(loss_start) # scalar. avg across batch\n",
    "           tf.summary.scalar('loss_start', self.loss_start) # log to tensorboard\n",
    "\n",
    "           # Calculate loss for prediction of end position\n",
    "           loss_end = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=self.logits_end, labels=self.ans_span[:, 1])\n",
    "           self.loss_end = tf.reduce_mean(loss_end)\n",
    "           tf.summary.scalar('loss_end', self.loss_end)\n",
    "\n",
    "           # Add the two losses\n",
    "           self.loss = self.loss_start + self.loss_end\n",
    "           tf.summary.scalar('loss', self.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(Hout,Sout,embeddings,word2id,rnn_outputs,x,y):\n",
    "    state_size = 512\n",
    "    batch_size = Hout.shape[0]\n",
    "    num_steps = Sout[1]\n",
    "    num_classes = embeddings[1]\n",
    "    num_layers = 2\n",
    "    initializer = Hout\n",
    "    \n",
    "    with tf.variable_scope('softmax'):\n",
    "        W = tf.get_variable('W', [state_size, num_classes])\n",
    "        b = tf.get_variable('b', [num_classes], initializer=tf.constant_initializer(0.0))\n",
    "    #reshape rnn_outputs and y so we can get the logits in a single matmul\n",
    "    rnn_outputs = tf.reshape(rnn_outputs, [-1, state_size])\n",
    "    y_reshaped = tf.reshape(y, [-1])\n",
    "    logits = tf.matmul(rnn_outputs, W) + b\n",
    "    losses = tf.reshape(tf.nn.sparse_softmax_cross_entropy_with_logits(logits, y_reshaped),[batch_size, num_steps])\n",
    "    loss_by_timestep = tf.reduce_mean(losses, reduction_indices=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_embedding_layer(sentence_ids,emb_matrix):\n",
    "    \"\"\"\n",
    "    Adds word embedding layer to the graph.\n",
    "\n",
    "    Inputs:\n",
    "      emb_matrix: shape (400002, embedding_size).\n",
    "      The Glove vectors, plus vectors for PAD and UNK.\n",
    "    \"\"\"\n",
    "    #with vs.variable_scope(\"embeddings\"):\n",
    "\n",
    "    # Note: the embedding matrix is a tf.constant which means it's not a trainable parameter\n",
    "    embedding_matrix = tf.constant(emb_matrix, dtype=tf.float32, name=\"emb_matrix\") # shape (400002, embedding_size)\n",
    "\n",
    "    # Get the word embeddings for the caption\n",
    "    # using the placeholders caption\n",
    "    #cap_embs = embedding_ops.embedding_lookup(embedding_matrix, sentence_ids) # shape (batch_size, context_len, embedding_size)\n",
    "    cap_embs = tf.nn.embedding_lookup(embedding_matrix, sentence_ids)\n",
    "       \n",
    "    return cap_embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = model(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Data (incomplete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_ids = [line.strip() for line in open(\"id_data/train_ids.csv\", 'r')]\n",
    "filename = \"c3d_data/sub_activitynet_v1-3.c3d.hdf5\"\n",
    "video_feature_representation = h5py.File(filename, 'r')\n",
    "train_ids = [\"v_--0edUL8zmA\",\"v_hHiPEAiYKv0\",\"v_u2uoYvo8J5s\",\"v_c_NlYvL96y0\",\"v_sJFgo9H6zNo\"]\n",
    "video_data = dict()\n",
    "for videoid in train_ids:\n",
    "    print(videoid)\n",
    "    proposals_df = pd.read_csv('prop_data/' + videoid + '.csv',sep=' ')\n",
    "    c3d_features = video_feature_representation[videoid]['c3d_features'].value\n",
    "    max_frames = c3d_features.shape[0]\n",
    "    print(max_frames)\n",
    "    \n",
    "    for i in range(proposals_df.shape[0]):\n",
    "        f_init = proposals_df[\"f-init\"][i]\n",
    "        f_end =  proposals_df[\"f-end\"][i]\n",
    "        if (f_init < max_frames) and (f_end > 0):\n",
    "            if f_init < 0:\n",
    "                f_init = 0\n",
    "            if f_end > max_frames:\n",
    "                f_end = max_frames\n",
    "        \n",
    "            #print((f_init,f_end))\n",
    "            #print(c3d_features[f_init:f_end,:].shape)\n",
    "            h = temporal_pooling(c3d_features[f_init:f_end,:], mode=\"max\")\n",
    "            if i == 0:\n",
    "                H = h\n",
    "            else:\n",
    "                H = np.column_stack((H,h))\n",
    "        else:\n",
    "            proposals_df.drop(proposals_df.index[i])\n",
    "    video_data[videoid] = H\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
